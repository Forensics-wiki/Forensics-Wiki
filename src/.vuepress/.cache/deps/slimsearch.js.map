{
  "version": 3,
  "sources": ["../../../../node_modules/slimsearch/src/SearchableMap/TreeIterator.ts", "../../../../node_modules/slimsearch/src/SearchableMap/fuzzySearch.ts", "../../../../node_modules/slimsearch/src/SearchableMap/SearchableMap.ts", "../../../../node_modules/slimsearch/src/info.ts", "../../../../node_modules/slimsearch/src/constant.ts", "../../../../node_modules/slimsearch/src/utils.ts", "../../../../node_modules/slimsearch/src/warning.ts", "../../../../node_modules/slimsearch/src/term.ts", "../../../../node_modules/slimsearch/src/add.ts", "../../../../node_modules/slimsearch/src/defaults.ts", "../../../../node_modules/slimsearch/src/results.ts", "../../../../node_modules/slimsearch/src/search.ts", "../../../../node_modules/slimsearch/src/autoSuggest.ts", "../../../../node_modules/slimsearch/src/SearchIndex.ts", "../../../../node_modules/slimsearch/src/init.ts", "../../../../node_modules/slimsearch/src/vacuum.ts", "../../../../node_modules/slimsearch/src/remove.ts", "../../../../node_modules/slimsearch/src/replace.ts"],
  "sourcesContent": ["import { type Entry, type LeafType, type RadixTree } from \"./types.js\";\n\nconst ENTRIES = \"ENTRIES\";\n\nconst KEYS = \"KEYS\";\n\nconst VALUES = \"VALUES\";\n\nconst LEAF = \"\" as LeafType;\n\ninterface Iterators<T> {\n  ENTRIES: Entry<T>;\n  KEYS: string;\n  VALUES: T;\n}\n\ntype Kind<T> = keyof Iterators<T>;\ntype Result<T, K extends keyof Iterators<T>> = Iterators<T>[K];\n\ntype IteratorPath<T> = {\n  node: RadixTree<T>;\n  keys: string[];\n}[];\n\nexport type IterableSet<T> = {\n  _tree: RadixTree<T>;\n  _prefix: string;\n};\n\n/**\n * @private\n */\nclass TreeIterator<T, K extends Kind<T>> implements Iterator<Result<T, K>> {\n  set: IterableSet<T>;\n  _type: K;\n  _path: IteratorPath<T>;\n\n  constructor(set: IterableSet<T>, type: K) {\n    const node = set._tree;\n    const keys = Array.from(node.keys());\n\n    this.set = set;\n    this._type = type;\n    this._path = keys.length > 0 ? [{ node, keys }] : [];\n  }\n\n  next(): IteratorResult<Result<T, K>> {\n    const value = this.dive();\n\n    this.backtrack();\n\n    return value;\n  }\n\n  dive(): IteratorResult<Result<T, K>> {\n    if (this._path.length === 0) return { done: true, value: undefined };\n\n    const { node, keys } = last(this._path)!;\n\n    if (last(keys) === LEAF) return { done: false, value: this.result() };\n\n    const child = node.get(last(keys)!)!;\n\n    this._path.push({ node: child, keys: Array.from(child.keys()) });\n\n    return this.dive();\n  }\n\n  backtrack(): void {\n    if (this._path.length === 0) return;\n\n    const keys = last(this._path)!.keys;\n\n    keys.pop();\n    if (keys.length > 0) return;\n\n    this._path.pop();\n    this.backtrack();\n  }\n\n  key(): string {\n    return (\n      this.set._prefix +\n      this._path\n        .map(({ keys }) => last(keys))\n        .filter((key) => key !== LEAF)\n        .join(\"\")\n    );\n  }\n\n  value(): T {\n    return last(this._path)!.node.get(LEAF)!;\n  }\n\n  result(): Result<T, K> {\n    switch (this._type) {\n      case VALUES:\n        return this.value() as Result<T, K>;\n      case KEYS:\n        return this.key() as Result<T, K>;\n      default:\n        return [this.key(), this.value()] as Result<T, K>;\n    }\n  }\n\n  [Symbol.iterator](): TreeIterator<T, K> {\n    return this;\n  }\n}\n\nconst last = <T>(array: T[]): T | undefined => {\n  return array[array.length - 1];\n};\n\nexport { TreeIterator, ENTRIES, KEYS, VALUES, LEAF };\n", "/* eslint-disable no-labels */\nimport { LEAF } from \"./TreeIterator.js\";\nimport { type RadixTree } from \"./types.js\";\n\nexport type FuzzyResult<T> = [T, number];\n\nexport type FuzzyResults<T> = Map<string, FuzzyResult<T>>;\n\nexport const fuzzySearch = <Value = any>(\n  node: RadixTree<Value>,\n  query: string,\n  maxDistance: number,\n): FuzzyResults<Value> => {\n  const results: FuzzyResults<Value> = new Map();\n\n  if (query === undefined) return results;\n\n  // Number of columns in the Levenshtein matrix.\n  const n = query.length + 1;\n\n  // Matching terms can never be longer than N + maxDistance.\n  const m = n + maxDistance;\n\n  // Fill first matrix row and column with numbers: 0 1 2 3 ...\n  const matrix = new Uint8Array(m * n).fill(maxDistance + 1);\n\n  for (let j = 0; j < n; ++j) matrix[j] = j;\n  for (let i = 1; i < m; ++i) matrix[i * n] = i;\n\n  recurse(node, query, maxDistance, results, matrix, 1, n, \"\");\n\n  return results;\n};\n\n// Modified version of http://stevehanov.ca/blog/?id=114\n\n// This builds a Levenshtein matrix for a given query and continuously updates\n// it for nodes in the radix tree that fall within the given maximum edit\n// distance. Keeping the same matrix around is beneficial especially for larger\n// edit distances.\n//\n//           k   a   t   e   <-- query\n//       0   1   2   3   4\n//   c   1   1   2   3   4\n//   a   2   2   1   2   3\n//   t   3   3   2   1  [2]  <-- edit distance\n//   ^\n//   ^ term in radix tree, rows are added and removed as needed\n\nconst recurse = <Value = any>(\n  node: RadixTree<Value>,\n  query: string,\n  maxDistance: number,\n  results: FuzzyResults<Value>,\n  matrix: Uint8Array,\n  m: number,\n  n: number,\n  prefix: string,\n): void => {\n  const offset = m * n;\n\n  key: for (const key of node.keys())\n    if (key === LEAF) {\n      // We've reached a leaf node. Check if the edit distance acceptable and\n      // store the result if it is.\n      const distance = matrix[offset - 1];\n\n      if (distance <= maxDistance)\n        results.set(prefix, [node.get(key)!, distance]);\n    } else {\n      // Iterate over all characters in the key. Update the Levenshtein matrix\n      // and check if the minimum distance in the last row is still within the\n      // maximum edit distance. If it is, we can recurse over all child nodes.\n      let i = m;\n\n      for (let pos = 0; pos < key.length; ++pos, ++i) {\n        const char = key[pos];\n        const thisRowOffset = n * i;\n        const prevRowOffset = thisRowOffset - n;\n\n        // Set the first column based on the previous row, and initialize the\n        // minimum distance in the current row.\n        let minDistance = matrix[thisRowOffset];\n\n        const jmin = Math.max(0, i - maxDistance - 1);\n        const jmax = Math.min(n - 1, i + maxDistance);\n\n        // Iterate over remaining columns (characters in the query).\n        for (let j = jmin; j < jmax; ++j) {\n          const different = char !== query[j];\n\n          // It might make sense to only read the matrix positions used for\n          // deletion/insertion if the characters are different. But we want to\n          // avoid conditional reads for performance reasons.\n          const rpl = matrix[prevRowOffset + j] + +different;\n          const del = matrix[prevRowOffset + j + 1] + 1;\n          const ins = matrix[thisRowOffset + j] + 1;\n\n          const dist = (matrix[thisRowOffset + j + 1] = Math.min(\n            rpl,\n            del,\n            ins,\n          ));\n\n          if (dist < minDistance) minDistance = dist;\n        }\n\n        // Because distance will never decrease, we can stop. There will be no\n        // matching child nodes.\n        if (minDistance > maxDistance) continue key;\n      }\n\n      recurse(\n        node.get(key)!,\n        query,\n        maxDistance,\n        results,\n        matrix,\n        i,\n        n,\n        prefix + key,\n      );\n    }\n};\n", "/* eslint-disable no-labels */\nimport { ENTRIES, KEYS, LEAF, TreeIterator, VALUES } from \"./TreeIterator.js\";\nimport { type FuzzyResults, fuzzySearch } from \"./fuzzySearch.js\";\nimport { type Entry, type Path, type RadixTree } from \"./types.js\";\n\n/**\n * A class implementing the same interface as a standard JavaScript\n * [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map)\n * with string keys, but adding support for efficiently searching entries with\n * prefix or fuzzy search. This class is used internally by [[SlimSearch]] as\n * the inverted index data structure. The implementation is a radix tree\n * (compressed prefix tree).\n *\n * Since this class can be of general utility beyond _SlimSearch_, it is\n * exported by the `slimsearch` package and can be imported (or required) as\n * `slimsearch/SearchableMap`.\n *\n * @typeParam T  The type of the values stored in the map.\n */\nexport class SearchableMap<T = any> {\n  /**\n   * @internal\n   */\n  _tree: RadixTree<T>;\n\n  /**\n   * @internal\n   */\n  _prefix: string;\n\n  private _size: number | undefined = undefined;\n\n  /**\n   * The constructor is normally called without arguments, creating an empty\n   * map. In order to create a [[SearchableMap]] from an iterable or from an\n   * object, check [[SearchableMap.from]] and [[SearchableMap.fromObject]].\n   *\n   * The constructor arguments are for internal use, when creating derived\n   * mutable views of a map at a prefix.\n   */\n  constructor(tree: RadixTree<T> = new Map(), prefix = \"\") {\n    this._tree = tree;\n    this._prefix = prefix;\n  }\n\n  /**\n   * Creates and returns a mutable view of this [[SearchableMap]], containing only\n   * entries that share the given prefix.\n   *\n   * ### Usage:\n   *\n   * ```js\n   * const map = new SearchableMap()\n   * map.set(\"unicorn\", 1)\n   * map.set(\"universe\", 2)\n   * map.set(\"university\", 3)\n   * map.set(\"unique\", 4)\n   * map.set(\"hello\", 5)\n   *\n   * const uni = map.atPrefix(\"uni\")\n   * uni.get(\"unique\") // => 4\n   * uni.get(\"unicorn\") // => 1\n   * uni.get(\"hello\") // => undefined\n   *\n   * const univer = map.atPrefix(\"univer\")\n   * univer.get(\"unique\") // => undefined\n   * univer.get(\"universe\") // => 2\n   * univer.get(\"university\") // => 3\n   * ```\n   *\n   * @param prefix  The prefix\n   * @return A [[SearchableMap]] representing a mutable view of the original Map at the given prefix\n   */\n  atPrefix(prefix: string): SearchableMap<T> {\n    if (!prefix.startsWith(this._prefix)) throw new Error(\"Mismatched prefix\");\n\n    const [node, path] = trackDown(\n      this._tree,\n      prefix.slice(this._prefix.length),\n    );\n\n    if (node === undefined) {\n      const [parentNode, key] = last(path);\n\n      for (const k of parentNode!.keys())\n        if (k !== LEAF && k.startsWith(key)) {\n          const node = new Map();\n\n          node.set(k.slice(key.length), parentNode!.get(k)!);\n\n          return new SearchableMap<T>(node, prefix);\n        }\n    }\n\n    return new SearchableMap<T>(node, prefix);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/clear\n   */\n  clear(): void {\n    this._size = undefined;\n    this._tree.clear();\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/delete\n   * @param key  Key to delete\n   */\n  delete(key: string): void {\n    this._size = undefined;\n\n    return remove(this._tree, key);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/entries\n   * @return An iterator iterating through `[key, value]` entries.\n   */\n  entries(): TreeIterator<T, \"ENTRIES\"> {\n    return new TreeIterator(this, ENTRIES);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/forEach\n   * @param fn  Iteration function\n   */\n  forEach(fn: (key: string, value: T, map: SearchableMap) => void): void {\n    for (const [key, value] of this) fn(key, value, this);\n  }\n\n  /**\n   * Returns a Map of all the entries that have a key within the given edit\n   * distance from the search key. The keys of the returned Map are the matching\n   * keys, while the values are two-element arrays where the first element is\n   * the value associated to the key, and the second is the edit distance of the\n   * key to the search key.\n   *\n   * ### Usage:\n   *\n   * ```js\n   * const map = new SearchableMap()\n   * map.set('hello', 'world')\n   * map.set('hell', 'yeah')\n   * map.set('ciao', 'mondo')\n   *\n   * // Get all entries that match the key 'hallo' with a maximum edit distance of 2\n   * map.fuzzyGet('hallo', 2)\n   * // => Map(2) { 'hello' => ['world', 1], 'hell' => ['yeah', 2] }\n   *\n   * // In the example, the \"hello\" key has value \"world\" and edit distance of 1\n   * // (change \"e\" to \"a\"), the key \"hell\" has value \"yeah\" and edit distance of 2\n   * // (change \"e\" to \"a\", delete \"o\")\n   * ```\n   *\n   * @param key  The search key\n   * @param maxEditDistance  The maximum edit distance (Levenshtein)\n   * @return A Map of the matching keys to their value and edit distance\n   */\n  fuzzyGet(key: string, maxEditDistance: number): FuzzyResults<T> {\n    return fuzzySearch<T>(this._tree, key, maxEditDistance);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/get\n   * @param key  Key to get\n   * @return Value associated to the key, or `undefined` if the key is not\n   * found.\n   */\n  get(key: string): T | undefined {\n    const node = lookup<T>(this._tree, key);\n\n    return node !== undefined ? node.get(LEAF) : undefined;\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/has\n   * @param key  Key\n   * @return True if the key is in the map, false otherwise\n   */\n  has(key: string): boolean {\n    const node = lookup(this._tree, key);\n\n    return node !== undefined && node.has(LEAF);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/keys\n   * @return An `Iterable` iterating through keys\n   */\n  keys(): TreeIterator<T, \"KEYS\"> {\n    return new TreeIterator(this, KEYS);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/set\n   * @param key  Key to set\n   * @param value  Value to associate to the key\n   * @return The [[SearchableMap]] itself, to allow chaining\n   */\n  set(key: string, value: T): SearchableMap<T> {\n    if (typeof key !== \"string\") throw new Error(\"key must be a string\");\n\n    this._size = undefined;\n    const node = createPath(this._tree, key);\n\n    node.set(LEAF, value);\n\n    return this;\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/size\n   */\n  get size(): number {\n    if (this._size) return this._size;\n\n    /** @ignore */\n    this._size = 0;\n\n    const iter = this.entries();\n\n    while (!iter.next().done) this._size += 1;\n\n    return this._size;\n  }\n\n  /**\n   * Updates the value at the given key using the provided function. The function\n   * is called with the current value at the key, and its return value is used as\n   * the new value to be set.\n   *\n   * ### Example:\n   *\n   * ```js\n   * // Increment the current value by one\n   * searchableMap.update('somekey', (currentValue) => currentValue == null ? 0 : currentValue + 1)\n   * ```\n   *\n   * If the value at the given key is or will be an object, it might not require\n   * re-assignment. In that case it is better to use `fetch()`, because it is\n   * faster.\n   *\n   * @param key  The key to update\n   * @param fn  The function used to compute the new value from the current one\n   * @return The [[SearchableMap]] itself, to allow chaining\n   */\n  update(key: string, fn: (value: T | undefined) => T): SearchableMap<T> {\n    if (typeof key !== \"string\") throw new Error(\"key must be a string\");\n\n    this._size = undefined;\n    const node = createPath(this._tree, key);\n\n    node.set(LEAF, fn(node.get(LEAF)));\n\n    return this;\n  }\n\n  /**\n   * Fetches the value of the given key. If the value does not exist, calls the\n   * given function to create a new value, which is inserted at the given key\n   * and subsequently returned.\n   *\n   * ### Example:\n   *\n   * ```js\n   * const map = searchableMap.fetch('somekey', () => new Map())\n   * map.set('foo', 'bar')\n   * ```\n   *\n   * @param key  The key to update\n   * @param defaultValue  A function that creates a new value if the key does not exist\n   * @return The existing or new value at the given key\n   */\n  fetch(key: string, initial: () => T): T {\n    if (typeof key !== \"string\") throw new Error(\"key must be a string\");\n\n    this._size = undefined;\n    const node = createPath(this._tree, key);\n\n    let value = node.get(LEAF);\n\n    if (value === undefined) node.set(LEAF, (value = initial()));\n\n    return value;\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/values\n   * @return An `Iterable` iterating through values.\n   */\n  values(): TreeIterator<T, \"VALUES\"> {\n    return new TreeIterator(this, VALUES);\n  }\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map/@@iterator\n   */\n  [Symbol.iterator](): TreeIterator<T, \"ENTRIES\"> {\n    return this.entries();\n  }\n\n  /**\n   * Creates a [[SearchableMap]] from an `Iterable` of entries\n   *\n   * @param entries  Entries to be inserted in the [[SearchableMap]]\n   * @return A new [[SearchableMap]] with the given entries\n   */\n  static from<T = any>(\n    entries: Iterable<Entry<T>> | Entry<T>[],\n  ): SearchableMap<T> {\n    const tree = new SearchableMap<T>();\n\n    for (const [key, value] of entries) tree.set(key, value);\n\n    return tree;\n  }\n\n  /**\n   * Creates a [[SearchableMap]] from the iterable properties of a JavaScript object\n   *\n   * @param object  Object of entries for the [[SearchableMap]]\n   * @return A new [[SearchableMap]] with the given entries\n   */\n  static fromObject<T = any>(object: { [key: string]: T }): SearchableMap<T> {\n    return SearchableMap.from<T>(Object.entries(object));\n  }\n}\n\nconst trackDown = <T = any>(\n  tree: RadixTree<T> | undefined,\n  key: string,\n  path: Path<T> = [],\n): [RadixTree<T> | undefined, Path<T>] => {\n  if (key.length === 0 || tree == null) return [tree, path];\n\n  for (const treeKey of tree.keys())\n    if (treeKey !== LEAF && key.startsWith(treeKey)) {\n      path.push([tree, treeKey]); // performance: update in place\n\n      return trackDown(tree.get(treeKey), key.slice(treeKey.length), path);\n    }\n\n  path.push([tree, key]); // performance: update in place\n\n  return trackDown(undefined, \"\", path);\n};\n\nconst lookup = <T = any>(\n  tree: RadixTree<T>,\n  key: string,\n): RadixTree<T> | undefined => {\n  if (key.length === 0 || tree == null) return tree;\n\n  for (const treeKey of tree.keys())\n    if (treeKey !== LEAF && key.startsWith(treeKey))\n      return lookup(tree.get(treeKey)!, key.slice(treeKey.length));\n};\n\n// Create a path in the radix tree for the given key, and returns the deepest\n// node. This function is in the hot path for indexing. It avoids unnecessary\n// string operations and recursion for performance.\nconst createPath = <T = any>(node: RadixTree<T>, key: string): RadixTree<T> => {\n  const keyLength = key.length;\n\n  outer: for (let pos = 0; node && pos < keyLength; ) {\n    // Check whether this key is a candidate: the first characters must match.\n    for (const k of node.keys())\n      if (k !== LEAF && key[pos] === k[0]) {\n        const len = Math.min(keyLength - pos, k.length);\n\n        // Advance offset to the point where key and k no longer match.\n        let offset = 1;\n\n        while (offset < len && key[pos + offset] === k[offset]) ++offset;\n\n        const child = node.get(k)!;\n\n        if (offset === k.length) {\n          // The existing key is shorter than the key we need to create.\n          node = child;\n        } else {\n          // Partial match: we need to insert an intermediate node to contain\n          // both the existing subtree and the new node.\n          const intermediate = new Map();\n\n          intermediate.set(k.slice(offset), child);\n          node.set(key.slice(pos, pos + offset), intermediate);\n          node.delete(k);\n          node = intermediate;\n        }\n\n        pos += offset;\n        continue outer;\n      }\n\n    // Create a final child node to contain the final suffix of the key.\n    const child = new Map();\n\n    node.set(key.slice(pos), child);\n\n    return child;\n  }\n\n  return node;\n};\n\nconst remove = <T = any>(tree: RadixTree<T>, key: string): void => {\n  const [node, path] = trackDown(tree, key);\n\n  if (node === undefined) return;\n\n  node.delete(LEAF);\n\n  if (node.size === 0) {\n    cleanup(path);\n  } else if (node.size === 1) {\n    const [key, value] = (<\n      IteratorResult<[string, RadixTree<T>], [string, RadixTree<T>]>\n    >node.entries().next()).value;\n\n    merge(path, key, value);\n  }\n};\n\nconst cleanup = <T = any>(path: Path<T>): void => {\n  if (path.length === 0) return;\n\n  const [node, key] = last(path);\n\n  node!.delete(key);\n\n  if (node!.size === 0) {\n    cleanup(path.slice(0, -1));\n  } else if (node!.size === 1) {\n    const [key, value] = (<\n      IteratorResult<[string, RadixTree<T>], [string, RadixTree<T>]>\n    >node!.entries().next()).value;\n\n    if (key !== LEAF) merge(path.slice(0, -1), key, value);\n  }\n};\n\nconst merge = <T = any>(\n  path: Path<T>,\n  key: string,\n  value: RadixTree<T>,\n): void => {\n  if (path.length === 0) return;\n\n  const [node, nodeKey] = last(path);\n\n  node!.set(nodeKey + key, value);\n  node!.delete(nodeKey);\n};\n\nconst last = <T = any>(array: T[]): T => {\n  return array[array.length - 1];\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\n\n/**\n * Returns `true` if a document with the given ID is present in the index and\n * available for search, `false` otherwise\n *\n * @param searchIndex The search Index\n * @param id  The document ID\n */\nexport const has = <Document, ID>(\n  searchIndex: SearchIndex<Document>,\n  id: ID,\n): boolean => searchIndex._idToShortId.has(id);\n\n/**\n * Returns the stored fields (as configured in the `storeFields` constructor\n * option) for the given document ID. Returns `undefined` if the document is\n * not present in the index.\n *\n * @param searchIndex The search Index\n * @param id  The document ID\n */\nexport const getStoredFields = <Document, ID>(\n  searchIndex: SearchIndex<Document>,\n  id: ID,\n): Record<string, unknown> | undefined => {\n  const shortId = searchIndex._idToShortId.get(id);\n\n  if (shortId == null) return undefined;\n\n  return searchIndex._storedFields.get(shortId);\n};\n", "// This regular expression matches any Unicode space or punctuation character\n// Adapted from https://unicode.org/cldr/utility/list-unicodeset.jsp?a=%5Cp%7BZ%7D%5Cp%7BP%7D&abb=on&c=on&esc=on\nexport const SPACE_OR_PUNCTUATION =\n  /[\\n\\r -#%-*,-/:;?@[-\\]_{}\\u00A0\\u00A1\\u00A7\\u00AB\\u00B6\\u00B7\\u00BB\\u00BF\\u037E\\u0387\\u055A-\\u055F\\u0589\\u058A\\u05BE\\u05C0\\u05C3\\u05C6\\u05F3\\u05F4\\u0609\\u060A\\u060C\\u060D\\u061B\\u061E\\u061F\\u066A-\\u066D\\u06D4\\u0700-\\u070D\\u07F7-\\u07F9\\u0830-\\u083E\\u085E\\u0964\\u0965\\u0970\\u09FD\\u0A76\\u0AF0\\u0C77\\u0C84\\u0DF4\\u0E4F\\u0E5A\\u0E5B\\u0F04-\\u0F12\\u0F14\\u0F3A-\\u0F3D\\u0F85\\u0FD0-\\u0FD4\\u0FD9\\u0FDA\\u104A-\\u104F\\u10FB\\u1360-\\u1368\\u1400\\u166E\\u1680\\u169B\\u169C\\u16EB-\\u16ED\\u1735\\u1736\\u17D4-\\u17D6\\u17D8-\\u17DA\\u1800-\\u180A\\u1944\\u1945\\u1A1E\\u1A1F\\u1AA0-\\u1AA6\\u1AA8-\\u1AAD\\u1B5A-\\u1B60\\u1BFC-\\u1BFF\\u1C3B-\\u1C3F\\u1C7E\\u1C7F\\u1CC0-\\u1CC7\\u1CD3\\u2000-\\u200A\\u2010-\\u2029\\u202F-\\u2043\\u2045-\\u2051\\u2053-\\u205F\\u207D\\u207E\\u208D\\u208E\\u2308-\\u230B\\u2329\\u232A\\u2768-\\u2775\\u27C5\\u27C6\\u27E6-\\u27EF\\u2983-\\u2998\\u29D8-\\u29DB\\u29FC\\u29FD\\u2CF9-\\u2CFC\\u2CFE\\u2CFF\\u2D70\\u2E00-\\u2E2E\\u2E30-\\u2E4F\\u3000-\\u3003\\u3008-\\u3011\\u3014-\\u301F\\u3030\\u303D\\u30A0\\u30FB\\uA4FE\\uA4FF\\uA60D-\\uA60F\\uA673\\uA67E\\uA6F2-\\uA6F7\\uA874-\\uA877\\uA8CE\\uA8CF\\uA8F8-\\uA8FA\\uA8FC\\uA92E\\uA92F\\uA95F\\uA9C1-\\uA9CD\\uA9DE\\uA9DF\\uAA5C-\\uAA5F\\uAADE\\uAADF\\uAAF0\\uAAF1\\uABEB\\uFD3E\\uFD3F\\uFE10-\\uFE19\\uFE30-\\uFE52\\uFE54-\\uFE61\\uFE63\\uFE68\\uFE6A\\uFE6B\\uFF01-\\uFF03\\uFF05-\\uFF0A\\uFF0C-\\uFF0F\\uFF1A\\uFF1B\\uFF1F\\uFF20\\uFF3B-\\uFF3D\\uFF3F\\uFF5B\\uFF5D\\uFF5F-\\uFF65]+/u;\n\nexport const OR = \"or\";\nexport const AND = \"and\";\nexport const AND_NOT = \"and_not\";\n", "import { AND, AND_NOT, OR } from \"./constant.js\";\nimport {\n  type BM25Params,\n  type MatchInfo,\n  type SearchOptions,\n} from \"./typings.js\";\n\nexport const assignUniqueTerm = (target: string[], term: string): void => {\n  // Avoid adding duplicate terms.\n  if (!target.includes(term)) target.push(term);\n};\n\nexport const assignUniqueTerms = (\n  target: string[],\n  source: readonly string[],\n): void => {\n  // Avoid adding duplicate terms.\n  for (const term of source) if (!target.includes(term)) target.push(term);\n};\n\ninterface Scored {\n  score: number;\n}\n\nexport const byScore = ({ score: a }: Scored, { score: b }: Scored): number =>\n  b - a;\n\nexport const createMap = <K, V>(): Map<K, V> => new Map<K, V>();\n\nexport const objectToNumericMap = <Value>(object: {\n  [key: string]: Value;\n}): Map<number, Value> => {\n  const map = new Map<number, Value>();\n\n  for (const key of Object.keys(object))\n    map.set(parseInt(key, 10), object[key]);\n\n  return map;\n};\n\nexport const getOwnProperty = (object: any, property: string): unknown =>\n  Object.prototype.hasOwnProperty.call(object, property)\n    ? // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n      object[property]\n    : undefined;\n\ninterface RawResultValue {\n  // Intermediate score, before applying the final score based on number of\n  // matched terms.\n  score: number;\n\n  // Set of all query terms that were matched. They may not be present in the\n  // text exactly in the case of prefix/fuzzy matches. We must check for\n  // uniqueness before adding a new term. This is much faster than using a set,\n  // because the number of elements is relatively small.\n  terms: string[];\n\n  // All terms that were found in the content, including the fields in which\n  // they were present. This object will be provided as part of the final search\n  // results.\n  match: MatchInfo;\n}\n\nexport type RawResult = Map<number, RawResultValue>;\n\nexport type CombinatorFunction = (a: RawResult, b: RawResult) => RawResult;\n\nexport const combinators: { [kind: string]: CombinatorFunction } = {\n  [OR]: (a: RawResult, b: RawResult) => {\n    for (const docId of b.keys()) {\n      const existing = a.get(docId);\n\n      if (existing == null) {\n        a.set(docId, b.get(docId)!);\n      } else {\n        const { score, terms, match } = b.get(docId)!;\n\n        existing.score = existing.score + score;\n        existing.match = Object.assign(existing.match, match);\n        assignUniqueTerms(existing.terms, terms);\n      }\n    }\n\n    return a;\n  },\n  [AND]: (a: RawResult, b: RawResult) => {\n    const combined = new Map();\n\n    for (const docId of b.keys()) {\n      const existing = a.get(docId);\n\n      if (existing == null) continue;\n\n      const { score, terms, match } = b.get(docId)!;\n\n      assignUniqueTerms(existing.terms, terms);\n      combined.set(docId, {\n        score: existing.score + score,\n        terms: existing.terms,\n        match: Object.assign(existing.match, match),\n      });\n    }\n\n    return combined;\n  },\n  [AND_NOT]: (a: RawResult, b: RawResult) => {\n    for (const docId of b.keys()) a.delete(docId);\n\n    return a;\n  },\n};\n\nexport const calcBM25Score = (\n  termFreq: number,\n  matchingCount: number,\n  totalCount: number,\n  fieldLength: number,\n  avgFieldLength: number,\n  bm25params: BM25Params,\n): number => {\n  const { k, b, d } = bm25params;\n  const invDocFreq = Math.log(\n    1 + (totalCount - matchingCount + 0.5) / (matchingCount + 0.5),\n  );\n\n  return (\n    invDocFreq *\n    (d +\n      (termFreq * (k + 1)) /\n        (termFreq + k * (1 - b + (b * fieldLength) / avgFieldLength)))\n  );\n};\n\nexport type QuerySpec = {\n  prefix: boolean;\n  fuzzy: number | boolean;\n  term: string;\n};\n\nexport const termToQuerySpec =\n  (options: SearchOptions) =>\n  (term: string, i: number, terms: string[]): QuerySpec => {\n    const fuzzy =\n      typeof options.fuzzy === \"function\"\n        ? options.fuzzy(term, i, terms)\n        : options.fuzzy || false;\n    const prefix =\n      typeof options.prefix === \"function\"\n        ? options.prefix(term, i, terms)\n        : options.prefix === true;\n\n    return { term, fuzzy, prefix };\n  };\n", "import { type SearchIndex } from \"./SearchIndex.js\";\n\nexport const warnDocumentChanged = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  shortDocumentId: number,\n  fieldId: number,\n  term: string,\n): void => {\n  for (const fieldName of Object.keys(searchIndex._fieldIds))\n    if (searchIndex._fieldIds[fieldName] === fieldId) {\n      searchIndex._options.logger(\n        \"warn\",\n        // eslint-disable-next-line @typescript-eslint/restrict-template-expressions\n        `SlimSearch: document with ID ${searchIndex._documentIds.get(\n          shortDocumentId,\n        )} has changed before removal: term \"${term}\" was not present in field \"${fieldName}\". Removing a document after it has changed can corrupt the index!`,\n        \"version_conflict\",\n      );\n\n      return;\n    }\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { createMap } from \"./utils.js\";\nimport { warnDocumentChanged } from \"./warning.js\";\n\n/**\n * @ignore\n */\nexport const addTerm = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  fieldId: number,\n  documentId: number,\n  term: string,\n): void => {\n  const indexData = searchIndex._index.fetch(term, createMap);\n\n  let fieldIndex = indexData.get(fieldId);\n\n  if (fieldIndex == null) {\n    fieldIndex = new Map();\n    fieldIndex.set(documentId, 1);\n    indexData.set(fieldId, fieldIndex);\n  } else {\n    const docs = fieldIndex.get(documentId);\n\n    fieldIndex.set(documentId, (docs || 0) + 1);\n  }\n};\n\nexport const removeTerm = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  fieldId: number,\n  documentId: number,\n  term: string,\n): void => {\n  if (!searchIndex._index.has(term)) {\n    warnDocumentChanged(searchIndex, documentId, fieldId, term);\n\n    return;\n  }\n\n  const indexData = searchIndex._index.fetch(term, createMap);\n\n  const fieldIndex = indexData.get(fieldId);\n\n  if (fieldIndex == null || fieldIndex.get(documentId) == null)\n    warnDocumentChanged(searchIndex, documentId, fieldId, term);\n  else if (fieldIndex.get(documentId)! <= 1)\n    if (fieldIndex.size <= 1) indexData.delete(fieldId);\n    else fieldIndex.delete(documentId);\n  else fieldIndex.set(documentId, fieldIndex.get(documentId)! - 1);\n\n  if (searchIndex._index.get(term)!.size === 0) searchIndex._index.delete(term);\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { has } from \"./info.js\";\nimport { addTerm } from \"./term.js\";\n\nconst addFieldLength = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documentId: number,\n  fieldId: number,\n  count: number,\n  length: number,\n): void => {\n  let fieldLengths = searchIndex._fieldLength.get(documentId);\n\n  if (fieldLengths == null)\n    searchIndex._fieldLength.set(documentId, (fieldLengths = []));\n  fieldLengths[fieldId] = length;\n\n  const averageFieldLength = searchIndex._avgFieldLength[fieldId] || 0;\n  const totalFieldLength = averageFieldLength * count + length;\n\n  searchIndex._avgFieldLength[fieldId] = totalFieldLength / (count + 1);\n};\n\nconst addDocumentId = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documentId: ID,\n): number => {\n  const shortDocumentId = searchIndex._nextId;\n\n  searchIndex._idToShortId.set(documentId, shortDocumentId);\n  searchIndex._documentIds.set(shortDocumentId, documentId);\n  searchIndex._documentCount += 1;\n  searchIndex._nextId += 1;\n\n  return shortDocumentId;\n};\n\nconst saveStoredFields = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documentId: number,\n  doc: Document,\n): void => {\n  const { storeFields, extractField } = searchIndex._options;\n\n  if (storeFields == null || storeFields.length === 0) return;\n\n  let documentFields = searchIndex._storedFields.get(documentId);\n\n  if (documentFields == null)\n    searchIndex._storedFields.set(documentId, (documentFields = {}));\n\n  for (const fieldName of storeFields) {\n    const fieldValue = extractField(doc, fieldName);\n\n    if (fieldValue !== undefined) documentFields[fieldName] = fieldValue;\n  }\n};\n\n/**\n * Adds a document to the index\n *\n * @param searchIndex  The search index\n * @param document  The document to be indexed\n */\nexport const add = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  document: Document,\n): void => {\n  const { extractField, tokenize, processTerm, fields, idField } =\n    searchIndex._options;\n  const id = extractField(document, idField);\n\n  if (id == null)\n    throw new Error(`SlimSearch: document does not have ID field \"${idField}\"`);\n\n  if (has(searchIndex, id)) throw new Error(`SlimSearch: duplicate ID ${id}`);\n\n  // @ts-ignore\n  const shortDocumentId = addDocumentId(searchIndex, id);\n\n  saveStoredFields(searchIndex, shortDocumentId, document);\n\n  for (const field of fields) {\n    const fieldValue = extractField(document, field);\n\n    if (fieldValue == null) continue;\n\n    const tokens = tokenize(fieldValue.toString(), field);\n    const fieldId = searchIndex._fieldIds[field];\n\n    const uniqueTerms = new Set(tokens).size;\n\n    addFieldLength(\n      searchIndex,\n      shortDocumentId,\n      fieldId,\n      searchIndex._documentCount - 1,\n      uniqueTerms,\n    );\n\n    for (const term of tokens) {\n      const processedTerm = processTerm(term, field);\n\n      if (Array.isArray(processedTerm))\n        for (const t of processedTerm)\n          addTerm(searchIndex, fieldId, shortDocumentId, t);\n      else if (processedTerm)\n        addTerm(searchIndex, fieldId, shortDocumentId, processedTerm);\n    }\n  }\n};\n\n/**\n * Adds all the given documents to the index\n *\n * @param searchIndex  The search index\n * @param documents  An array of documents to be indexed\n */\nexport const addAll = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documents: readonly Document[],\n): void => {\n  for (const document of documents) add(searchIndex, document);\n};\n\n/**\n * Adds all the given documents to the index asynchronously.\n *\n * Returns a promise that resolves (to `undefined`) when the indexing is done.\n * This method is useful when index many documents, to avoid blocking the main\n * thread. The indexing is performed asynchronously and in chunks.\n *\n * @param searchIndex  The search index\n * @param documents  An array of documents to be indexed\n * @param options  Configuration options\n * @return A promise resolving to `undefined` when the indexing is done\n */\nexport const addAllAsync = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documents: readonly Document[],\n  options: { chunkSize?: number } = {},\n): Promise<void> => {\n  const { chunkSize = 10 } = options;\n  const acc: { chunk: Document[]; promise: Promise<void> } = {\n    chunk: [],\n    promise: Promise.resolve(),\n  };\n\n  const { chunk, promise } = documents.reduce(\n    ({ chunk, promise }, document, index) => {\n      chunk.push(document);\n      if ((index + 1) % chunkSize === 0)\n        return {\n          chunk: [],\n          promise: promise\n            .then(() => new Promise((resolve) => setTimeout(resolve, 0)))\n            .then(() => addAll(searchIndex, chunk)),\n        };\n      else return { chunk, promise };\n    },\n    acc,\n  );\n\n  return promise.then(() => addAll(searchIndex, chunk));\n};\n", "import { AND, OR, SPACE_OR_PUNCTUATION } from \"./constant.js\";\nimport { type BM25Params, type LogLevel } from \"./typings.js\";\nimport { getOwnProperty } from \"./utils.js\";\n\nexport const defaultBM25params: BM25Params = { k: 1.2, b: 0.7, d: 0.5 };\n\nexport const defaultOptions = {\n  idField: \"id\",\n  extractField: (document: any, fieldName: string): unknown =>\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\n    document[fieldName],\n  tokenize: (text: string): string[] => text.split(SPACE_OR_PUNCTUATION),\n  processTerm: (term: string): string => term.toLowerCase(),\n  fields: undefined,\n  searchOptions: undefined,\n  storeFields: [],\n  logger: (level: LogLevel, message: string): void => {\n    if (typeof console?.[level] === \"function\") console[level](message);\n  },\n  autoVacuum: true,\n};\n\nexport const defaultSearchOptions = {\n  combineWith: OR,\n  prefix: false,\n  fuzzy: false,\n  maxFuzzy: 6,\n  boost: {},\n  weights: { fuzzy: 0.45, prefix: 0.375 },\n  bm25: defaultBM25params,\n};\n\nexport const defaultAutoSuggestOptions = {\n  combineWith: AND,\n  prefix: (_term: string, index: number, terms: string[]): boolean =>\n    index === terms.length - 1,\n};\n\nexport const defaultVacuumOptions = { batchSize: 1000, batchWait: 10 };\nexport const defaultVacuumConditions = { minDirtFactor: 0.1, minDirtCount: 20 };\n\nexport const defaultAutoVacuumOptions = {\n  ...defaultVacuumOptions,\n  ...defaultVacuumConditions,\n};\n\n/**\n * Returns the default value of an option. It will throw an error if no option\n * with the given name exists.\n *\n * @param optionName  Name of the option\n * @return The default value of the given option\n *\n * ### Usage:\n *\n * ```js\n * // Get default tokenizer\n * getDefaultValue('tokenize')\n *\n * // Get default term processor\n * getDefaultValue('processTerm')\n *\n * // Unknown options will throw an error\n * getDefaultValue('notExisting')\n * // => throws 'SlimSearch: unknown option \"notExisting\"'\n * ```\n */\nexport const getDefaultValue = (optionName: string): unknown => {\n  // eslint-disable-next-line no-prototype-builtins\n  if (defaultOptions.hasOwnProperty(optionName))\n    return getOwnProperty(defaultOptions, optionName);\n  else throw new Error(`SlimSearch: unknown option \"${optionName}\"`);\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { OR } from \"./constant.js\";\nimport { defaultSearchOptions } from \"./defaults.js\";\nimport { removeTerm } from \"./term.js\";\nimport { type BM25Params, type Query, type SearchOptions } from \"./typings.js\";\nimport {\n  type QuerySpec,\n  type RawResult,\n  assignUniqueTerm,\n  calcBM25Score,\n  combinators,\n  getOwnProperty,\n  termToQuerySpec,\n} from \"./utils.js\";\n\nexport interface SearchOptionsWithDefaults<ID = any> extends SearchOptions<ID> {\n  boost: { [fieldName: string]: number };\n\n  weights: { fuzzy: number; prefix: number };\n\n  prefix: boolean | ((term: string, index: number, terms: string[]) => boolean);\n\n  fuzzy:\n    | boolean\n    | number\n    | ((term: string, index: number, terms: string[]) => boolean | number);\n\n  maxFuzzy: number;\n\n  combineWith: string;\n\n  bm25: BM25Params;\n}\n\nexport type DocumentTermFrequencies = Map<number, number>;\n\ntype FieldTermData = Map<number, DocumentTermFrequencies>;\n\nconst combineResults = (results: RawResult[], combineWith = OR): RawResult => {\n  if (results.length === 0) return new Map();\n\n  const operator = combineWith.toLowerCase();\n\n  return results.reduce(combinators[operator]) || new Map();\n};\n\nconst termResults = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  sourceTerm: string,\n  derivedTerm: string,\n  termWeight: number,\n  fieldTermData: FieldTermData | undefined,\n  fieldBoosts: { [field: string]: number },\n  boostDocumentFn:\n    | ((id: ID, term: string, storedFields?: Record<string, unknown>) => number)\n    | undefined,\n  bm25params: BM25Params,\n  results: RawResult = new Map(),\n): RawResult => {\n  if (fieldTermData == null) return results;\n\n  for (const field of Object.keys(fieldBoosts)) {\n    const fieldBoost = fieldBoosts[field];\n    const fieldId = searchIndex._fieldIds[field];\n\n    const fieldTermFrequencies = fieldTermData.get(fieldId);\n\n    if (fieldTermFrequencies == null) continue;\n\n    let matchingFields = fieldTermFrequencies.size;\n    const avgFieldLength = searchIndex._avgFieldLength[fieldId];\n\n    for (const docId of fieldTermFrequencies.keys()) {\n      if (!searchIndex._documentIds.has(docId)) {\n        removeTerm(searchIndex, fieldId, docId, derivedTerm);\n        matchingFields -= 1;\n        continue;\n      }\n\n      const docBoost = boostDocumentFn\n        ? boostDocumentFn(\n            searchIndex._documentIds.get(docId)!,\n            derivedTerm,\n            searchIndex._storedFields.get(docId),\n          )\n        : 1;\n\n      if (!docBoost) continue;\n\n      const termFreq = fieldTermFrequencies.get(docId)!;\n      const fieldLength = searchIndex._fieldLength.get(docId)![fieldId];\n\n      // NOTE: The total number of fields is set to the number of documents\n      // `this._documentCount`. It could also make sense to use the number of\n      // documents where the current field is non-blank as a normalization\n      // factor. This will make a difference in scoring if the field is rarely\n      // present. This is currently not supported, and may require further\n      // analysis to see if it is a valid use case.\n      const rawScore = calcBM25Score(\n        termFreq,\n        matchingFields,\n        searchIndex._documentCount,\n        fieldLength,\n        avgFieldLength,\n        bm25params,\n      );\n      const weightedScore = termWeight * fieldBoost * docBoost * rawScore;\n\n      const result = results.get(docId);\n\n      if (result) {\n        result.score += weightedScore;\n        assignUniqueTerm(result.terms, sourceTerm);\n        const match = <string[]>getOwnProperty(result.match, derivedTerm);\n\n        if (match) match.push(field);\n        else result.match[derivedTerm] = [field];\n      } else {\n        results.set(docId, {\n          score: weightedScore,\n          terms: [sourceTerm],\n          match: { [derivedTerm]: [field] },\n        });\n      }\n    }\n  }\n\n  return results;\n};\n\nconst executeQuerySpec = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  query: QuerySpec,\n  searchOptions: SearchOptions,\n): RawResult => {\n  const options: SearchOptionsWithDefaults = {\n    ...searchIndex._options.searchOptions,\n    ...searchOptions,\n  };\n\n  const boosts = (options.fields || searchIndex._options.fields).reduce(\n    (boosts, field) => ({\n      ...boosts,\n      [field]: getOwnProperty(options.boost, field) || 1,\n    }),\n    {},\n  );\n\n  const { boostDocument, weights, maxFuzzy, bm25: bm25params } = options;\n\n  const { fuzzy: fuzzyWeight, prefix: prefixWeight } = {\n    ...defaultSearchOptions.weights,\n    ...weights,\n  };\n\n  const data = searchIndex._index.get(query.term);\n  const results = termResults(\n    searchIndex,\n    query.term,\n    query.term,\n    1,\n    data,\n    boosts,\n    boostDocument,\n    bm25params,\n  );\n\n  let prefixMatches;\n  let fuzzyMatches;\n\n  if (query.prefix) prefixMatches = searchIndex._index.atPrefix(query.term);\n\n  if (query.fuzzy) {\n    const fuzzy = query.fuzzy === true ? 0.2 : query.fuzzy;\n    const maxDistance =\n      fuzzy < 1\n        ? Math.min(maxFuzzy, Math.round(query.term.length * fuzzy))\n        : fuzzy;\n\n    if (maxDistance)\n      fuzzyMatches = searchIndex._index.fuzzyGet(query.term, maxDistance);\n  }\n\n  if (prefixMatches)\n    for (const [term, data] of prefixMatches) {\n      const distance = term.length - query.term.length;\n\n      if (!distance) continue;\n      // Skip exact match.\n\n      // Delete the term from fuzzy results (if present) if it is also a\n      // prefix result. This entry will always be scored as a prefix result.\n      fuzzyMatches?.delete(term);\n\n      // Weight gradually approaches 0 as distance goes to infinity, with the\n      // weight for the hypothetical distance 0 being equal to prefixWeight.\n      // The rate of change is much lower than that of fuzzy matches to\n      // account for the fact that prefix matches stay more relevant than\n      // fuzzy matches for longer distances.\n      const weight =\n        (prefixWeight * term.length) / (term.length + 0.3 * distance);\n\n      termResults(\n        searchIndex,\n        query.term,\n        term,\n        weight,\n        data,\n        boosts,\n        boostDocument,\n        bm25params,\n        results,\n      );\n    }\n\n  if (fuzzyMatches)\n    for (const term of fuzzyMatches.keys()) {\n      const [data, distance] = fuzzyMatches.get(term)!;\n\n      if (!distance) continue;\n      // Skip exact match.\n\n      // Weight gradually approaches 0 as distance goes to infinity, with the\n      // weight for the hypothetical distance 0 being equal to fuzzyWeight.\n      const weight = (fuzzyWeight * term.length) / (term.length + distance);\n\n      termResults(\n        searchIndex,\n        query.term,\n        term,\n        weight,\n        data,\n        boosts,\n        boostDocument,\n        bm25params,\n        results,\n      );\n    }\n\n  return results;\n};\n\nexport const executeQuery = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  query: Query,\n  searchOptions: SearchOptions<ID> = {},\n): RawResult => {\n  if (typeof query !== \"string\") {\n    const options = { ...searchOptions, ...query, queries: undefined };\n    const results = query.queries.map((subQuery) =>\n      executeQuery(searchIndex, subQuery, options),\n    );\n\n    return combineResults(results, options.combineWith);\n  }\n\n  const {\n    tokenize,\n    processTerm,\n    searchOptions: globalSearchOptions,\n  } = searchIndex._options;\n  const options = {\n    tokenize,\n    processTerm,\n    ...globalSearchOptions,\n    ...searchOptions,\n  };\n  const { tokenize: searchTokenize, processTerm: searchProcessTerm } = options;\n  // @ts-ignore\n  const terms = searchTokenize(query)\n    // @ts-ignore\n    .flatMap((term: string) => searchProcessTerm(term))\n    .filter((term) => !!term) as string[];\n  // @ts-ignore\n  const queries: QuerySpec[] = terms.map(termToQuerySpec(options));\n  const results = queries.map((query) =>\n    // @ts-ignore\n    executeQuerySpec(searchIndex, query, options),\n  );\n\n  return combineResults(results, options.combineWith);\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { executeQuery } from \"./results.js\";\nimport {\n  type Query,\n  type SearchOptions,\n  type SearchResult,\n} from \"./typings.js\";\nimport { byScore } from \"./utils.js\";\n\n/**\n * Search for documents matching the given search query.\n *\n * The result is a list of scored document IDs matching the query, sorted by\n * descending score, and each including data about which terms were matched and\n * in which fields.\n *\n * ### Basic usage:\n *\n * ```js\n * // Search for \"zen art motorcycle\" with default options: terms have to match\n * // exactly, and individual terms are joined with OR\n * search(searchIndex, 'zen art motorcycle')\n * // => [ { id: 2, score: 2.77258, match: { ... } }, { id: 4, score: 1.38629, match: { ... } } ]\n * ```\n *\n * ### Restrict search to specific fields:\n *\n * ```js\n * // Search only in the 'title' field\n * search(searchIndex, 'zen', { fields: ['title'] })\n * ```\n *\n * ### Field boosting:\n *\n * ```js\n * // Boost a field\n * search(searchIndex, 'zen', { boost: { title: 2 } })\n * ```\n *\n * ### Prefix search:\n *\n * ```js\n * // Search for \"moto\" with prefix search (it will match documents\n * // containing terms that start with \"moto\" or \"neuro\")\n * search(searchIndex, 'moto neuro', { prefix: true })\n * ```\n *\n * ### Fuzzy search:\n *\n * ```js\n * // Search for \"ismael\" with fuzzy search (it will match documents containing\n * // terms similar to \"ismael\", with a maximum edit distance of 0.2 term.length\n * // (rounded to nearest integer)\n * search(searchIndex, 'ismael', { fuzzy: 0.2 })\n * ```\n *\n * ### Combining strategies:\n *\n * ```js\n * // Mix of exact match, prefix search, and fuzzy search\n * search(searchIndex, 'ismael mob', {\n *  prefix: true,\n *  fuzzy: 0.2\n * })\n * ```\n *\n * ### Advanced prefix and fuzzy search:\n *\n * ```js\n * // Perform fuzzy and prefix search depending on the search term. Here\n * // performing prefix and fuzzy search only on terms longer than 3 characters\n * search(searchIndex, 'ismael mob', {\n *  prefix: term => term.length > 3\n *  fuzzy: term => term.length > 3 ? 0.2 : null\n * })\n * ```\n *\n * ### Combine with AND:\n *\n * ```js\n * // Combine search terms with AND (to match only documents that contain both\n * // \"motorcycle\" and \"art\")\n * search(searchIndex, 'motorcycle art', { combineWith: 'AND' })\n * ```\n *\n * ### Combine with AND_NOT:\n *\n * There is also an AND_NOT combinator, that finds documents that match the\n * first term, but do not match any of the other terms. This combinator is\n * rarely useful with simple queries, and is meant to be used with advanced\n * query combinations (see later for more details).\n *\n * ### Filtering results:\n *\n * ```js\n * // Filter only results in the 'fiction' category (assuming that 'category'\n * // is a stored field)\n * search(searchIndex, 'motorcycle art', {\n *   filter: (result) => result.category === 'fiction'\n * })\n * ```\n *\n * ### Advanced combination of queries:\n *\n * It is possible to combine different subqueries with OR, AND, and AND_NOT,\n * and even with different search options, by passing a query expression\n * tree object as the first argument, instead of a string.\n *\n * ```js\n * // Search for documents that contain \"zen\" and (\"motorcycle\" or \"archery\")\n * search(searchIndex, {\n *   combineWith: 'AND',\n *   queries: [\n *     'zen',\n *     {\n *       combineWith: 'OR',\n *       queries: ['motorcycle', 'archery']\n *     }\n *   ]\n * })\n *\n * // Search for documents that contain (\"apple\" or \"pear\") but not \"juice\" and\n * // not \"tree\"\n * search(searchIndex, {\n *   combineWith: 'AND_NOT',\n *   queries: [\n *     {\n *       combineWith: 'OR',\n *       queries: ['apple', 'pear']\n *     },\n *     'juice',\n *     'tree'\n *   ]\n * })\n * ```\n *\n * Each node in the expression tree can be either a string, or an object that\n * supports all `SearchOptions` fields, plus a `queries` array field for\n * subqueries.\n *\n * Note that, while this can become complicated to do by hand for complex or\n * deeply nested queries, it provides a formalized expression tree API for\n * external libraries that implement a parser for custom query languages.\n *\n * @param searchIndex Search Index\n * @param query  Search query\n * @param options  Search options. Each option, if not given, defaults to the corresponding value of `searchOptions` given to the constructor, or to the library default.\n */\nexport const search = <\n  Document,\n  ID,\n  Field extends Record<string, any> = Partial<Document>,\n>(\n  searchIndex: SearchIndex<Document, ID>,\n  query: Query,\n  searchOptions: SearchOptions<ID> = {},\n): SearchResult<ID, Field>[] => {\n  const combinedResults = executeQuery(searchIndex, query, searchOptions);\n\n  const results: SearchResult<ID, Field>[] = [];\n\n  for (const [docId, { score, terms, match }] of combinedResults) {\n    // Final score takes into account the number of matching QUERY terms.\n    // The end user will only receive the MATCHED terms.\n    const quality = terms.length;\n\n    const result = {\n      id: searchIndex._documentIds.get(docId)!,\n      score: score * quality,\n      terms: Object.keys(match),\n      match,\n    };\n\n    Object.assign(result, searchIndex._storedFields.get(docId));\n    if (searchOptions.filter == null || searchOptions.filter(result))\n      results.push(<SearchResult<ID, Field>>result);\n  }\n\n  results.sort(byScore);\n\n  return results;\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { search } from \"./search.js\";\nimport { type SearchOptions, type Suggestion } from \"./typings.js\";\nimport { byScore } from \"./utils.js\";\n\n/**\n * Provide suggestions for the given search query\n *\n * The result is a list of suggested modified search queries, derived from the\n * given search query, each with a relevance score, sorted by descending score.\n *\n * By default, it uses the same options used for search, except that by\n * default it performs prefix search on the last term of the query, and\n * combine terms with `'AND'` (requiring all query terms to match). Custom\n * options can be passed as a second argument. Defaults can be changed by\n * passing an `autoSuggestOptions` option when initializing the index.\n *\n * ### Basic usage:\n *\n * ```js\n * // Get suggestions for 'neuro':\n * autoSuggest(searchIndex, 'neuro')\n * // => [ { suggestion: 'neuromancer', terms: [ 'neuromancer' ], score: 0.46240 } ]\n * ```\n *\n * ### Multiple words:\n *\n * ```js\n * // Get suggestions for 'zen ar':\n * autoSuggest(searchIndex, 'zen ar')\n * // => [\n * //  { suggestion: 'zen archery art', terms: [ 'zen', 'archery', 'art' ], score: 1.73332 },\n * //  { suggestion: 'zen art', terms: [ 'zen', 'art' ], score: 1.21313 }\n * // ]\n * ```\n *\n * ### Fuzzy suggestions:\n *\n * ```js\n * // Correct spelling mistakes using fuzzy search:\n * autoSuggest(searchIndex, 'neromancer', { fuzzy: 0.2 })\n * // => [ { suggestion: 'neuromancer', terms: [ 'neuromancer' ], score: 1.03998 } ]\n * ```\n *\n * ### Filtering:\n *\n * ```js\n * // Get suggestions for 'zen ar', but only within the 'fiction' category\n * // (assuming that 'category' is a stored field):\n * autoSuggest(searchIndex, 'zen ar', {\n *   filter: (result) => result.category === 'fiction'\n * })\n * // => [\n * //  { suggestion: 'zen archery art', terms: [ 'zen', 'archery', 'art' ], score: 1.73332 },\n * //  { suggestion: 'zen art', terms: [ 'zen', 'art' ], score: 1.21313 }\n * // ]\n * ```\n *\n * @param searchIndex The search Index\n * @param queryString  Query string to be expanded into suggestions\n * @param options  Search options. The supported options and default values\n * are the same as for the `search` method, except that by default prefix\n * search is performed on the last term in the query, and terms are combined\n * with `'AND'`.\n * @return  A sorted array of suggestions sorted by relevance score.\n */\nexport const autoSuggest = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  queryString: string,\n  options: SearchOptions<ID> = {},\n): Suggestion[] => {\n  options = { ...searchIndex._options.autoSuggestOptions, ...options };\n\n  const suggestions: Map<\n    string,\n    Omit<Suggestion, \"suggestion\"> & { count: number }\n  > = new Map();\n\n  for (const { score, terms } of search(searchIndex, queryString, options)) {\n    const phrase = terms.join(\" \");\n    const suggestion = suggestions.get(phrase);\n\n    if (suggestion != null) {\n      suggestion.score += score;\n      suggestion.count += 1;\n    } else {\n      suggestions.set(phrase, { score, terms, count: 1 });\n    }\n  }\n\n  const results = [];\n\n  for (const [suggestion, { score, terms, count }] of suggestions)\n    results.push({ suggestion, terms, score: score / count });\n\n  results.sort(byScore);\n\n  return results;\n};\n", "import { SearchableMap } from \"./SearchableMap/SearchableMap.js\";\nimport {\n  defaultAutoSuggestOptions,\n  defaultAutoVacuumOptions,\n  defaultOptions,\n  defaultSearchOptions,\n  defaultVacuumConditions,\n} from \"./defaults.js\";\nimport {\n  type DocumentTermFrequencies,\n  type SearchOptionsWithDefaults,\n} from \"./results.js\";\nimport {\n  type AutoVacuumOptions,\n  type IndexObject,\n  type LogLevel,\n  type SearchIndexOptions,\n  type SearchOptions,\n  type SerializedIndexEntry,\n  type VacuumConditions,\n} from \"./typings.js\";\n\ninterface OptionsWithDefaults<Document = any, ID = any>\n  extends Omit<SearchIndexOptions<Document, ID>, \"processTerm\" | \"tokenize\"> {\n  storeFields: string[];\n\n  idField: string;\n\n  extractField: (document: Document, fieldName: string) => string;\n\n  tokenize: (text: string, fieldName: string) => string[];\n\n  processTerm: (\n    term: string,\n    fieldName: string,\n  ) => string | string[] | null | undefined | false;\n\n  logger: (level: LogLevel, message: string, code?: string) => void;\n\n  autoVacuum: false | AutoVacuumOptions;\n\n  searchOptions: SearchOptionsWithDefaults<ID>;\n\n  autoSuggestOptions: SearchOptions<ID>;\n}\n\nexport type FieldTermData = Map<number, DocumentTermFrequencies>;\n\n/**\n *\n * @typeParam Document  The type of the documents being indexed.\n * @typeParam ID  The id type of the documents being indexed.\n *\n * ### Basic example:\n *\n * ```js\n * const documents = [\n *   {\n *     id: 1,\n *     title: 'Moby Dick',\n *     text: 'Call me Ishmael. Some years ago...',\n *     category: 'fiction'\n *   },\n *   {\n *     id: 2,\n *     title: 'Zen and the Art of Motorcycle Maintenance',\n *     text: 'I can see by my watch...',\n *     category: 'fiction'\n *   },\n *   {\n *     id: 3,\n *     title: 'Neuromancer',\n *     text: 'The sky above the port was...',\n *     category: 'fiction'\n *   },\n *   {\n *     id: 4,\n *     title: 'Zen and the Art of Archery',\n *     text: 'At first sight it must seem...',\n *     category: 'non-fiction'\n *   },\n *   // ...and more\n * ]\n *\n * // Create a search engine that indexes the 'title' and 'text' fields for\n * // full-text search. Search results will include 'title' and 'category' (plus the\n * // id field, that is always stored and returned)\n * const searchIndex = createIndex({\n *   fields: ['title', 'text'],\n *   storeFields: ['title', 'category']\n * })\n *\n * // Add documents to the index\n * addAll(searchIndex, documents)\n *\n * // Search for documents:\n * const results = search(searchIndex, 'zen art motorcycle')\n * // => [\n * //   { id: 2, title: 'Zen and the Art of Motorcycle Maintenance', category: 'fiction', score: 2.77258 },\n * //   { id: 4, title: 'Zen and the Art of Archery', category: 'non-fiction', score: 1.38629 }\n * // ]\n * ```\n */\nexport class SearchIndex<Document = any, ID = any> {\n  _options: OptionsWithDefaults<Document>;\n  _index: SearchableMap<FieldTermData>;\n  _documentCount: number;\n  _documentIds: Map<number, ID>;\n  _idToShortId: Map<ID, number>;\n  _fieldIds: { [key: string]: number };\n  _fieldLength: Map<number, number[]>;\n  _avgFieldLength: number[];\n  _nextId: number;\n  _storedFields: Map<number, Record<string, unknown>>;\n  _dirtCount: number;\n  _currentVacuum: Promise<void> | null;\n  _enqueuedVacuum: Promise<void> | null;\n  _enqueuedVacuumConditions: VacuumConditions | undefined;\n\n  constructor(options: SearchIndexOptions<Document, ID>) {\n    if (options?.fields == null)\n      throw new Error('SlimSearch: option \"fields\" must be provided');\n\n    const autoVacuum =\n      options.autoVacuum == null || options.autoVacuum === true\n        ? defaultAutoVacuumOptions\n        : options.autoVacuum;\n\n    // @ts-ignore\n    this._options = {\n      ...defaultOptions,\n      ...options,\n      autoVacuum,\n      searchOptions: {\n        ...defaultSearchOptions,\n        ...(options.searchOptions || {}),\n      },\n      autoSuggestOptions: {\n        ...defaultAutoSuggestOptions,\n        ...(options.autoSuggestOptions || {}),\n      },\n    };\n\n    this._index = new SearchableMap();\n\n    this._documentCount = 0;\n\n    this._documentIds = new Map();\n\n    this._idToShortId = new Map();\n\n    // Fields are defined during initialization, don't change, are few in\n    // number, rarely need iterating over, and have string keys. Therefore in\n    // this case an object is a better candidate than a Map to store the mapping\n    // from field key to ID.\n    this._fieldIds = {};\n\n    this._fieldLength = new Map();\n\n    this._avgFieldLength = [];\n\n    this._nextId = 0;\n\n    this._storedFields = new Map();\n\n    this._dirtCount = 0;\n\n    this._currentVacuum = null;\n\n    this._enqueuedVacuum = null;\n    this._enqueuedVacuumConditions = defaultVacuumConditions;\n\n    this.addFields(this._options.fields);\n  }\n\n  /**\n   * Is `true` if a vacuuming operation is ongoing, `false` otherwise\n   */\n  get isVacuuming(): boolean {\n    return this._currentVacuum != null;\n  }\n\n  /**\n   * The number of documents discarded since the most recent vacuuming\n   */\n  get dirtCount(): number {\n    return this._dirtCount;\n  }\n\n  /**\n   * A number between 0 and 1 giving an indication about the proportion of\n   * documents that are discarded, and can therefore be cleaned up by vacuuming.\n   * A value close to 0 means that the index is relatively clean, while a higher\n   * value means that the index is relatively dirty, and vacuuming could release\n   * memory.\n   */\n  get dirtFactor(): number {\n    return this._dirtCount / (1 + this._documentCount + this._dirtCount);\n  }\n\n  /**\n   * Total number of documents available to search\n   */\n  get documentCount(): number {\n    return this._documentCount;\n  }\n\n  /**\n   * Number of terms in the index\n   */\n  get termCount(): number {\n    return this._index.size;\n  }\n\n  /**\n   * Allows serialization of the index to JSON, to possibly store it and later\n   * deserialize it with `loadJSONIndex`.\n   *\n   * Normally one does not directly call this method, but rather call the\n   * standard JavaScript `JSON.stringify()` passing the `SearchIndex` instance,\n   * and JavaScript will internally call this method. Upon deserialization, one\n   * must pass to `loadJSONIndex` the same options used to create the original\n   * instance that was serialized.\n   *\n   * ### Usage:\n   *\n   * ```js\n   * // Serialize the index:\n   * let searchIndex = createIndex({ fields: ['title', 'text'] })\n   * addAll(searchIndex, documents)\n   * const json = JSON.stringify(index)\n   *\n   * // Later, to deserialize it:\n   * searchIndex = loadJSONIndex(json, { fields: ['title', 'text'] })\n   * ```\n   *\n   * @return A plain-object serializable representation of the search index.\n   */\n  toJSON(): IndexObject {\n    const index: [string, { [key: string]: SerializedIndexEntry }][] = [];\n\n    for (const [term, fieldIndex] of this._index) {\n      const data: { [key: string]: SerializedIndexEntry } = {};\n\n      for (const [fieldId, frequencies] of fieldIndex)\n        data[fieldId] = Object.fromEntries(frequencies);\n\n      index.push([term, data]);\n    }\n\n    return {\n      documentCount: this._documentCount,\n      nextId: this._nextId,\n      documentIds: Object.fromEntries(this._documentIds),\n      fieldIds: this._fieldIds,\n      fieldLength: Object.fromEntries(this._fieldLength),\n      averageFieldLength: this._avgFieldLength,\n      storedFields: Object.fromEntries(this._storedFields),\n      dirtCount: this._dirtCount,\n      index,\n      serializationVersion: 2,\n    };\n  }\n\n  /**\n   * @ignore\n   */\n  private addFields(fields: string[]): void {\n    for (let i = 0; i < fields.length; i++) this._fieldIds[fields[i]] = i;\n  }\n}\n", "/* eslint-disable @typescript-eslint/no-explicit-any */\nimport { type FieldTermData, SearchIndex } from \"./SearchIndex.js\";\nimport { SearchableMap } from \"./SearchableMap/SearchableMap.js\";\nimport { type DocumentTermFrequencies } from \"./results.js\";\nimport {\n  type IndexObject,\n  type SearchIndexOptions,\n  type SerializedIndexEntry,\n} from \"./typings.js\";\nimport { objectToNumericMap } from \"./utils.js\";\n\n/**\n * @param options  Configuration options\n *\n * ### Examples:\n *\n * ```js\n * // Create a search engine that indexes the 'title' and 'text' fields of your\n * // documents:\n * const searchIndex = createIndex({ fields: ['title', 'text'] })\n * ```\n *\n * ### ID Field:\n *\n * ```js\n * // Your documents are assumed to include a unique 'id' field, but if you want\n * // to use a different field for document identification, you can set the\n * // 'idField' option:\n * const searchIndex = createIndex({ idField: 'key', fields: ['title', 'text'] })\n * ```\n *\n * ### Options and defaults:\n *\n * ```js\n * // The full set of options (here with their default value) is:\n * const searchIndex = createIndex({\n *   // idField: field that uniquely identifies a document\n *   idField: 'id',\n *\n *   // extractField: function used to get the value of a field in a document.\n *   // By default, it assumes the document is a flat object with field names as\n *   // property keys and field values as string property values, but custom logic\n *   // can be implemented by setting this option to a custom extractor function.\n *   extractField: (document, fieldName) => document[fieldName],\n *\n *   // tokenize: function used to split fields into individual terms. By\n *   // default, it is also used to tokenize search queries, unless a specific\n *   // `tokenize` search option is supplied. When tokenizing an indexed field,\n *   // the field name is passed as the second argument.\n *   tokenize: (string, _fieldName) => string.split(SPACE_OR_PUNCTUATION),\n *\n *   // processTerm: function used to process each tokenized term before\n *   // indexing. It can be used for stemming and normalization. Return a falsy\n *   // value in order to discard a term. By default, it is also used to process\n *   // search queries, unless a specific `processTerm` option is supplied as a\n *   // search option. When processing a term from a indexed field, the field\n *   // name is passed as the second argument.\n *   processTerm: (term, _fieldName) => term.toLowerCase(),\n *\n *   // searchOptions: default search options, see the `search` method for\n *   // details\n *   searchOptions: undefined,\n *\n *   // fields: document fields to be indexed. Mandatory, but not set by default\n *   fields: undefined\n *\n *   // storeFields: document fields to be stored and returned as part of the\n *   // search results.\n *   storeFields: []\n * })\n * ```\n */\nexport const createIndex = <Document = any, ID = any>(\n  options: SearchIndexOptions<Document, ID>,\n): SearchIndex<Document, ID> => new SearchIndex(options);\n\nexport const loadIndex = <Document = any, ID = any>(\n  {\n    index,\n    documentCount,\n    nextId,\n    documentIds,\n    fieldIds,\n    fieldLength,\n    averageFieldLength,\n    storedFields,\n    dirtCount,\n    serializationVersion,\n  }: IndexObject,\n  options: SearchIndexOptions<Document, ID>,\n): SearchIndex<Document, ID> => {\n  if (serializationVersion !== 1 && serializationVersion !== 2)\n    throw new Error(\n      \"SlimSearch: cannot deserialize an index created with an incompatible version\",\n    );\n\n  const searchIndex = new SearchIndex(options);\n\n  searchIndex._documentCount = documentCount;\n  searchIndex._nextId = nextId;\n  searchIndex._documentIds = objectToNumericMap<ID>(documentIds);\n  searchIndex._idToShortId = new Map<ID, number>();\n  searchIndex._fieldIds = fieldIds;\n  searchIndex._fieldLength = objectToNumericMap(fieldLength);\n  searchIndex._avgFieldLength = averageFieldLength;\n  searchIndex._storedFields = objectToNumericMap(storedFields);\n  searchIndex._dirtCount = dirtCount || 0;\n  searchIndex._index = new SearchableMap();\n\n  for (const [shortId, id] of searchIndex._documentIds)\n    searchIndex._idToShortId.set(id, shortId);\n\n  for (const [term, data] of index) {\n    const dataMap = new Map() as FieldTermData;\n\n    for (const fieldId of Object.keys(data)) {\n      let indexEntry = data[fieldId];\n\n      // Version 1 used to nest the index entry inside a field called ds\n      if (serializationVersion === 1)\n        indexEntry = indexEntry.ds as unknown as SerializedIndexEntry;\n\n      dataMap.set(\n        parseInt(fieldId, 10),\n        objectToNumericMap(indexEntry) as DocumentTermFrequencies,\n      );\n    }\n\n    searchIndex._index.set(term, dataMap);\n  }\n\n  return searchIndex;\n};\n\n/**\n * Deserializes a JSON index (serialized with `JSON.stringify(index)`)\n * and instantiates a SearchIndex instance. It should be given the same options\n * originally used when serializing the index.\n *\n * ### Usage:\n *\n * ```js\n * // If the index was serialized with:\n * let index = createIndex({ fields: ['title', 'text'] })\n *\n * addAll(index, documents)\n *\n * const json = JSON.stringify(index)\n * // It can later be deserialized like this:\n * index = loadJSONIndex(json, { fields: ['title', 'text'] })\n * ```\n *\n * @param json  JSON-serialized index\n * @param options  configuration options, same as the constructor\n * @return An instance of SearchIndex deserialized from the given JSON.\n */\nexport const loadJSONIndex = <Document = any, ID = any>(\n  json: string,\n  options: SearchIndexOptions<Document, ID>,\n): SearchIndex<Document, ID> => {\n  if (options == null)\n    throw new Error(\n      \"SlimSearch: loadJSON should be given the same options used when serializing the index\",\n    );\n\n  return loadIndex(<IndexObject>JSON.parse(json), options);\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport {\n  defaultAutoVacuumOptions,\n  defaultVacuumConditions,\n  defaultVacuumOptions,\n} from \"./defaults.js\";\nimport { type VacuumConditions, type VacuumOptions } from \"./typings.js\";\n\nconst shouldVacuum = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  conditions?: VacuumConditions,\n): boolean => {\n  if (conditions == null) return true;\n\n  const {\n    minDirtCount = defaultAutoVacuumOptions.minDirtCount,\n    minDirtFactor = defaultAutoVacuumOptions.minDirtFactor,\n  } = conditions;\n\n  return (\n    searchIndex.dirtCount >= minDirtCount &&\n    searchIndex.dirtFactor >= minDirtFactor\n  );\n};\n\nconst doVacuum = async <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  options: VacuumOptions,\n  conditions?: VacuumConditions,\n): Promise<void> => {\n  const initialDirtCount = searchIndex._dirtCount;\n\n  if (shouldVacuum(searchIndex, conditions)) {\n    const batchSize = options.batchSize || defaultVacuumOptions.batchSize;\n    const batchWait = options.batchWait || defaultVacuumOptions.batchWait;\n    let i = 1;\n\n    for (const [term, fieldsData] of searchIndex._index) {\n      for (const [fieldId, fieldIndex] of fieldsData)\n        for (const [shortId] of fieldIndex) {\n          if (searchIndex._documentIds.has(shortId)) continue;\n\n          if (fieldIndex.size <= 1) fieldsData.delete(fieldId);\n          else fieldIndex.delete(shortId);\n        }\n\n      if (searchIndex._index.get(term)!.size === 0)\n        searchIndex._index.delete(term);\n\n      if (i % batchSize === 0)\n        await new Promise((resolve) => setTimeout(resolve, batchWait));\n\n      i += 1;\n    }\n\n    searchIndex._dirtCount -= initialDirtCount;\n  }\n\n  // Make the next lines always async, so they execute after this function returns\n  // eslint-disable-next-line @typescript-eslint/await-thenable\n  await null;\n\n  searchIndex._currentVacuum = searchIndex._enqueuedVacuum;\n  searchIndex._enqueuedVacuum = null;\n};\n\nconst conditionalVacuum = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  options: VacuumOptions,\n  conditions?: VacuumConditions,\n): Promise<void> => {\n  // If a vacuum is already ongoing, schedule another as soon as it finishes,\n  // unless there's already one enqueued. If one was already enqueued, do not\n  // enqueue another on top, but make sure that the conditions are the\n  // broadest.\n  if (searchIndex._currentVacuum) {\n    searchIndex._enqueuedVacuumConditions =\n      searchIndex._enqueuedVacuumConditions && conditions;\n    if (searchIndex._enqueuedVacuum != null) return searchIndex._enqueuedVacuum;\n\n    searchIndex._enqueuedVacuum = searchIndex._currentVacuum.then(() => {\n      const conditions = searchIndex._enqueuedVacuumConditions;\n\n      searchIndex._enqueuedVacuumConditions = defaultVacuumConditions;\n\n      return doVacuum(searchIndex, options, conditions);\n    });\n\n    return searchIndex._enqueuedVacuum;\n  }\n\n  if (shouldVacuum(searchIndex, conditions) === false) return Promise.resolve();\n\n  searchIndex._currentVacuum = doVacuum(searchIndex, options);\n\n  return searchIndex._currentVacuum;\n};\n\nexport const maybeAutoVacuum = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n): void => {\n  if (searchIndex._options.autoVacuum === false) return;\n\n  const { minDirtFactor, minDirtCount, batchSize, batchWait } =\n    searchIndex._options.autoVacuum;\n\n  void conditionalVacuum(\n    searchIndex,\n    { batchSize, batchWait },\n    { minDirtCount, minDirtFactor },\n  );\n};\n\n/**\n * Triggers a manual vacuuming, cleaning up references to discarded documents\n * from the inverted index\n *\n * Vacuuming is only useful for applications that use the\n * [[discard]] or [[replace]] methods.\n *\n * By default, vacuuming is performed automatically when needed (controlled by\n * the `autoVacuum` field in [[Options]]), so there is usually no need to call\n * this method, unless one wants to make sure to perform vacuuming at a\n * specific moment.\n *\n * Vacuuming traverses all terms in the inverted index in batches, and cleans\n * up references to discarded documents from the posting list, allowing memory\n * to be released.\n *\n * The method takes an optional object as argument with the following keys:\n *\n *   - `batchSize`: the size of each batch (1000 by default)\n *\n *   - `batchWait`: the number of milliseconds to wait between batches (10 by\n *   default)\n *\n * On large indexes, vacuuming could have a non-negligible cost: batching\n * avoids blocking the thread for long, diluting this cost so that it is not\n * negatively affecting the application. Nonetheless, this method should only\n * be called when necessary, and relying on automatic vacuuming is usually\n * better.\n *\n * It returns a promise that resolves (to undefined) when the clean up is\n * completed. If vacuuming is already ongoing at the time this method is\n * called, a new one is enqueued immediately after the ongoing one, and a\n * corresponding promise is returned. However, no more than one vacuuming is\n * enqueued on top of the ongoing one, even if this method is called more\n * times (enqueuing multiple ones would be useless).\n *\n * @param searchIndex Search Index\n * @param options  Configuration options for the batch size and delay. See\n * [[VacuumOptions]].\n */\nexport const vacuum = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  options: VacuumOptions = {},\n): Promise<void> => conditionalVacuum(searchIndex, options);\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { SearchableMap } from \"./SearchableMap/SearchableMap.js\";\nimport { removeTerm } from \"./term.js\";\nimport { maybeAutoVacuum } from \"./vacuum.js\";\n\nconst removeFieldLength = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  fieldId: number,\n  count: number,\n  length: number,\n): void => {\n  if (count === 1) {\n    searchIndex._avgFieldLength[fieldId] = 0;\n\n    return;\n  }\n\n  const totalFieldLength =\n    searchIndex._avgFieldLength[fieldId] * count - length;\n\n  searchIndex._avgFieldLength[fieldId] = totalFieldLength / (count - 1);\n};\n\n/**\n * Discards the document with the given ID, so it won't appear in search results\n *\n * It has the same visible effect of [[remove]] (both cause the\n * document to stop appearing in searches), but a different effect on the\n * internal data structures:\n *\n *   - [[remove]] requires passing the full document to be removed\n *   as argument, and removes it from the inverted index immediately.\n *\n *   - [[discard]] instead only needs the document ID, and works by\n *   marking the current version of the document as discarded, so it is\n *   immediately ignored by searches. This is faster and more convenient than\n *   `remove`, but the index is not immediately modified. To take care of\n *   that, vacuuming is performed after a certain number of documents are\n *   discarded, cleaning up the index and allowing memory to be released.\n *\n * After discarding a document, it is possible to re-add a new version, and\n * only the new version will appear in searches. In other words, discarding\n * and re-adding a document works exactly like removing and re-adding it. The\n * [[replace]] method can also be used to replace a document with a\n * new version.\n *\n * #### Details about vacuuming\n *\n * Repetitive calls to this method would leave obsolete document references in\n * the index, invisible to searches. Two mechanisms take care of cleaning up:\n * clean up during search, and vacuuming.\n *\n *   - Upon search, whenever a discarded ID is found (and ignored for the\n *   results), references to the discarded document are removed from the\n *   inverted index entries for the search terms. This ensures that subsequent\n *   searches for the same terms do not need to skip these obsolete references\n *   again.\n *\n *   - In addition, vacuuming is performed automatically by default (see the\n *   `autoVacuum` field in [[Options]]) after a certain number of documents\n *   are discarded. Vacuuming traverses all terms in the index, cleaning up\n *   all references to discarded documents. Vacuuming can also be triggered\n *   manually by calling [[vacuum]].\n *\n * @param searchIndex The search Index\n * @param id  The ID of the document to be discarded\n */\nexport const discard = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  id: ID,\n): void => {\n  const shortId = searchIndex._idToShortId.get(id);\n\n  if (shortId == null)\n    throw new Error(\n      `SlimSearch: cannot discard document with ID ${<string>(\n        id\n      )}: it is not in the index`,\n    );\n\n  searchIndex._idToShortId.delete(id);\n  searchIndex._documentIds.delete(shortId);\n  searchIndex._storedFields.delete(shortId);\n  (searchIndex._fieldLength.get(shortId) || []).forEach(\n    (fieldLength, fieldId) => {\n      removeFieldLength(\n        searchIndex,\n        fieldId,\n        searchIndex._documentCount,\n        fieldLength,\n      );\n    },\n  );\n\n  searchIndex._fieldLength.delete(shortId);\n\n  searchIndex._documentCount -= 1;\n  searchIndex._dirtCount += 1;\n\n  maybeAutoVacuum(searchIndex);\n};\n\n/**\n * Discards the documents with the given IDs, so they won't appear in search\n * results\n *\n * It is equivalent to calling [[discard]] for all the given IDs,\n * but with the optimization of triggering at most one automatic vacuuming at\n * the end.\n *\n * Note: to remove all documents from the index, it is faster and more\n * convenient to call [[removeAll]] with no argument, instead of\n * passing all IDs to this method.\n */\nexport const discardAll = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  ids: readonly ID[],\n): void => {\n  const autoVacuum = searchIndex._options.autoVacuum;\n\n  try {\n    searchIndex._options.autoVacuum = false;\n\n    for (const id of ids) discard(searchIndex, id);\n  } finally {\n    searchIndex._options.autoVacuum = autoVacuum;\n  }\n\n  maybeAutoVacuum(searchIndex);\n};\n\n/**\n * Removes the given document from the index.\n *\n * The document to remove must NOT have changed between indexing and removal,\n * otherwise the index will be corrupted.\n *\n * This method requires passing the full document to be removed (not just the\n * ID), and immediately removes the document from the inverted index, allowing\n * memory to be released. A convenient alternative is [[discard]],\n * which needs only the document ID, and has the same visible effect, but\n * delays cleaning up the index until the next vacuuming.\n *\n * @param searchIndex The search Index\n * @param document  The document to be removed\n */\nexport const remove = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  document: Document,\n): void => {\n  const { tokenize, processTerm, extractField, fields, idField } =\n    searchIndex._options;\n  const id = <ID>extractField(document, idField);\n\n  if (id == null)\n    throw new Error(`SlimSearch: document does not have ID field \"${idField}\"`);\n\n  const shortId = searchIndex._idToShortId.get(id);\n\n  if (shortId == null)\n    throw new Error(\n      `SlimSearch: cannot remove document with ID ${<string>(\n        id\n      )}: it is not in the index`,\n    );\n\n  for (const field of fields) {\n    const fieldValue = extractField(document, field);\n\n    if (fieldValue == null) continue;\n\n    const tokens = tokenize(fieldValue.toString(), field);\n    const fieldId = searchIndex._fieldIds[field];\n\n    const uniqueTerms = new Set(tokens).size;\n\n    removeFieldLength(\n      searchIndex,\n      fieldId,\n      searchIndex._documentCount,\n      uniqueTerms,\n    );\n\n    for (const term of tokens) {\n      const processedTerm = processTerm(term, field);\n\n      if (Array.isArray(processedTerm))\n        for (const t of processedTerm)\n          removeTerm(searchIndex, fieldId, shortId, t);\n      else if (processedTerm)\n        removeTerm(searchIndex, fieldId, shortId, processedTerm);\n    }\n  }\n\n  searchIndex._storedFields.delete(shortId);\n  searchIndex._documentIds.delete(shortId);\n  searchIndex._idToShortId.delete(id);\n  searchIndex._fieldLength.delete(shortId);\n  searchIndex._documentCount -= 1;\n};\n\n/**\n * Removes all the given documents from the index. If called with no arguments,\n * it removes _all_ documents from the index.\n *\n * @param searchIndex The search Index\n * @param documents  The documents to be removed. If this argument is omitted,\n * all documents are removed. Note that, for removing all documents, it is\n * more efficient to call this method with no arguments than to pass all\n * documents.\n */\nexport const removeAll = function removeAll<Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  documents?: readonly Document[],\n): void {\n  if (documents) {\n    for (const document of documents) remove(searchIndex, document);\n  } else if (arguments.length > 1) {\n    throw new Error(\n      \"Expected documents to be present. Omit the argument to remove all documents.\",\n    );\n  } else {\n    searchIndex._index = new SearchableMap();\n    searchIndex._documentCount = 0;\n    searchIndex._documentIds = new Map();\n    searchIndex._idToShortId = new Map();\n    searchIndex._fieldLength = new Map();\n    searchIndex._avgFieldLength = [];\n    searchIndex._storedFields = new Map();\n    searchIndex._nextId = 0;\n  }\n};\n", "import { type SearchIndex } from \"./SearchIndex.js\";\nimport { add } from \"./add.js\";\nimport { discard } from \"./remove.js\";\n\n/**\n * It replaces an existing document with the given updated version\n *\n * It works by discarding the current version and adding the updated one, so\n * it is functionally equivalent to calling [[discard]] followed by\n * [[add]]. The ID of the updated document should be the same as\n * the original one.\n *\n * Since it uses [[discard]] internally, this method relies on\n * vacuuming to clean up obsolete document references from the index, allowing\n * memory to be released (see [[discard]]).\n *\n * @param searchIndex The search Index\n * @param updatedDocument  The updated document to replace the old version\n * with\n */\nexport const replace = <Document, ID>(\n  searchIndex: SearchIndex<Document, ID>,\n  updatedDocument: Document,\n): void => {\n  const { idField, extractField } = searchIndex._options;\n  const id = <ID>extractField(updatedDocument, idField);\n\n  discard(searchIndex, id);\n  add(searchIndex, updatedDocument);\n};\n"],
  "mappings": ";;;;;AAEA,IAAMA,KAAU;AAAhB,IAEMC,IAAO;AAFb,IAIMC,IAAS;AAJf,IAMMC,IAAO;AAwBb,IAAMC,IAAN,MAA2E;EAKzE,YAAYC,GAAqBC,GAAS;AAJ1C;AACA;AACA;AAGE,UAAMC,IAAOF,EAAI,OACXG,IAAO,MAAM,KAAKD,EAAK,KAAM,CAAA;AAEnC,SAAK,MAAMF,GACX,KAAK,QAAQC,GACb,KAAK,QAAQE,EAAK,SAAS,IAAI,CAAC,EAAE,MAAAD,GAAM,MAAAC,EAAK,CAAC,IAAI,CACpD;EAAA;EAEA,OAAqC;AACnC,UAAMC,IAAQ,KAAK,KAAK;AAExB,WAAK,KAAA,UAAA,GAEEA;EACT;EAEA,OAAqC;AACnC,QAAI,KAAK,MAAM,WAAW;AAAG,aAAO,EAAE,MAAM,MAAM,OAAO,OAAU;AAEnE,UAAM,EAAE,MAAAF,GAAM,MAAAC,EAAK,IAAIE,EAAK,KAAK,KAAK;AAEtC,QAAIA,EAAKF,CAAI,MAAML;AAAM,aAAO,EAAE,MAAM,OAAO,OAAO,KAAK,OAAS,EAAA;AAEpE,UAAMQ,IAAQJ,EAAK,IAAIG,EAAKF,CAAI,CAAE;AAElC,WAAK,KAAA,MAAM,KAAK,EAAE,MAAMG,GAAO,MAAM,MAAM,KAAKA,EAAM,KAAM,CAAA,EAAE,CAAC,GAExD,KAAK,KAAA;EACd;EAEA,YAAkB;AAChB,QAAI,KAAK,MAAM,WAAW;AAAG;AAE7B,UAAMH,IAAOE,EAAK,KAAK,KAAK,EAAG;AAE/BF,MAAK,IAAI,GACL,EAAAA,EAAK,SAAS,OAElB,KAAK,MAAM,IAAI,GACf,KAAK,UACP;EAAA;EAEA,MAAc;AACZ,WACE,KAAK,IAAI,UACT,KAAK,MACF,IAAI,CAAC,EAAE,MAAAA,EAAK,MAAME,EAAKF,CAAI,CAAC,EAC5B,OAAQI,OAAQA,MAAQT,CAAI,EAC5B,KAAK,EAAE;EAEd;EAEA,QAAW;AACT,WAAOO,EAAK,KAAK,KAAK,EAAG,KAAK,IAAIP,CAAI;EACxC;EAEA,SAAuB;AACrB,YAAQ,KAAK,OACX;MAAA,KAAKD;AACH,eAAO,KAAK,MAAA;MACd,KAAKD;AACH,eAAO,KAAK,IAAA;MACd;AACE,eAAO,CAAC,KAAK,IAAO,GAAA,KAAK,MAAO,CAAA;IACpC;EACF;EAEA,CAAC,OAAO,QAAQ,IAAwB;AACtC,WAAO;EACT;AACF;AAEA,IAAMS,IAAWG,OACRA,EAAMA,EAAM,SAAS,CAAC;AAD/B,ICtGaC,KAAc,CACzBP,GACAQ,GACAC,MACwB;AACxB,QAAMC,IAA+B,oBAAI;AAEzC,MAAIF,MAAU;AAAW,WAAOE;AAGhC,QAAMC,IAAIH,EAAM,SAAS,GAGnBI,IAAID,IAAIF,GAGRI,IAAS,IAAI,WAAWD,IAAID,CAAC,EAAE,KAAKF,IAAc,CAAC;AAEzD,WAASK,IAAI,GAAGA,IAAIH,GAAG,EAAEG;AAAGD,MAAOC,CAAC,IAAIA;AACxC,WAASC,IAAI,GAAGA,IAAIH,GAAG,EAAEG;AAAGF,MAAOE,IAAIJ,CAAC,IAAII;AAE5C,SAAAC,EAAQhB,GAAMQ,GAAOC,GAAaC,GAASG,GAAQ,GAAGF,GAAG,EAAE,GAEpDD;AACT;AD8EA,IC7DMM,IAAU,CACdhB,GACAQ,GACAC,GACAC,GACAG,GACAD,GACAD,GACAM,MACS;AACT,QAAMC,IAASN,IAAID;AAEnBN;AAAK,eAAWA,KAAOL,EAAK,KAAK;AAC/B,UAAIK,MAAQT,GAAM;AAGhB,cAAMuB,IAAWN,EAAOK,IAAS,CAAC;AAE9BC,aAAYV,KACdC,EAAQ,IAAIO,GAAQ,CAACjB,EAAK,IAAIK,CAAG,GAAIc,CAAQ,CAAC;MAClD,OAAO;AAIL,YAAIJ,IAAIH;AAER,iBAASQ,IAAM,GAAGA,IAAMf,EAAI,QAAQ,EAAEe,GAAK,EAAEL,GAAG;AAC9C,gBAAMM,IAAOhB,EAAIe,CAAG,GACdE,IAAgBX,IAAII,GACpBQ,IAAgBD,IAAgBX;AAItC,cAAIa,IAAcX,EAAOS,CAAa;AAEtC,gBAAMG,IAAO,KAAK,IAAI,GAAGV,IAAIN,IAAc,CAAC,GACtCiB,IAAO,KAAK,IAAIf,IAAI,GAAGI,IAAIN,CAAW;AAG5C,mBAASK,IAAIW,GAAMX,IAAIY,GAAM,EAAEZ,GAAG;AAChC,kBAAMa,IAAYN,MAASb,EAAMM,CAAC,GAK5Bc,IAAMf,EAAOU,IAAgBT,CAAC,IAAI,CAACa,GACnCE,IAAMhB,EAAOU,IAAgBT,IAAI,CAAC,IAAI,GACtCgB,IAAMjB,EAAOS,IAAgBR,CAAC,IAAI,GAElCiB,IAAQlB,EAAOS,IAAgBR,IAAI,CAAC,IAAI,KAAK,IACjDc,GACAC,GACAC,CACF;AAEIC,gBAAOP,MAAaA,IAAcO;UACxC;AAIA,cAAIP,IAAcf;AAAa,qBAASJ;QAC1C;AAEAW,UACEhB,EAAK,IAAIK,CAAG,GACZG,GACAC,GACAC,GACAG,GACAE,GACAJ,GACAM,IAASZ,CACX;MACF;AACJ;ACxGO,IAAM2B,IAAN,MAAMA,GAAuB;EAqBlC,YAAYC,IAAqB,oBAAI,OAAOhB,IAAS,IAAI;AAjBzD;AAKA;AAEQ;AAWN,SAAK,QAAQgB,GACb,KAAK,UAAUhB;EACjB;EA8BA,SAASA,GAAkC;AACzC,QAAI,CAACA,EAAO,WAAW,KAAK,OAAO;AAAG,YAAM,IAAI,MAAM,mBAAmB;AAEzE,UAAM,CAACjB,GAAMkC,CAAI,IAAIC,EACnB,KAAK,OACLlB,EAAO,MAAM,KAAK,QAAQ,MAAM,CAClC;AAEA,QAAIjB,MAAS,QAAW;AACtB,YAAM,CAACoC,GAAY/B,CAAG,IAAIF,EAAK+B,CAAI;AAEnC,iBAAWG,KAAKD,EAAY,KAAK;AAC/B,YAAIC,MAAMzC,KAAQyC,EAAE,WAAWhC,CAAG,GAAG;AACnC,gBAAML,IAAO,oBAAI;AAEjB,iBAAAA,EAAK,IAAIqC,EAAE,MAAMhC,EAAI,MAAM,GAAG+B,EAAY,IAAIC,CAAC,CAAE,GAE1C,IAAIL,GAAiBhC,GAAMiB,CAAM;QAC1C;IACJ;AAEA,WAAO,IAAIe,GAAiBhC,GAAMiB,CAAM;EAC1C;EAKA,QAAc;AACZ,SAAK,QAAQ,QACb,KAAK,MAAM,MACb;EAAA;EAMA,OAAOZ,GAAmB;AACxB,WAAA,KAAK,QAAQ,QAENiC,GAAO,KAAK,OAAOjC,CAAG;EAC/B;EAMA,UAAsC;AACpC,WAAO,IAAIR,EAAa,MAAMJ,EAAO;EACvC;EAMA,QAAQ8C,GAA+D;AACrE,eAAW,CAAClC,GAAKH,CAAK,KAAK;AAAMqC,QAAGlC,GAAKH,GAAO,IAAI;EACtD;EA8BA,SAASG,GAAamC,GAA0C;AAC9D,WAAOjC,GAAe,KAAK,OAAOF,GAAKmC,CAAe;EACxD;EAQA,IAAInC,GAA4B;AAC9B,UAAML,IAAOyC,EAAU,KAAK,OAAOpC,CAAG;AAEtC,WAAOL,MAAS,SAAYA,EAAK,IAAIJ,CAAI,IAAI;EAC/C;EAOA,IAAIS,GAAsB;AACxB,UAAML,IAAOyC,EAAO,KAAK,OAAOpC,CAAG;AAEnC,WAAOL,MAAS,UAAaA,EAAK,IAAIJ,CAAI;EAC5C;EAMA,OAAgC;AAC9B,WAAO,IAAIC,EAAa,MAAMH,CAAI;EACpC;EAQA,IAAIW,GAAaH,GAA4B;AAC3C,QAAI,OAAOG,KAAQ;AAAU,YAAM,IAAI,MAAM,sBAAsB;AAEnE,WAAA,KAAK,QAAQ,QACAqC,EAAW,KAAK,OAAOrC,CAAG,EAElC,IAAIT,GAAMM,CAAK,GAEb;EACT;EAKA,IAAI,OAAe;AACjB,QAAI,KAAK;AAAO,aAAO,KAAK;AAG5B,SAAK,QAAQ;AAEb,UAAMyC,IAAO,KAAK,QAAA;AAElB,WAAO,CAACA,EAAK,KAAA,EAAO;AAAM,WAAK,SAAS;AAExC,WAAO,KAAK;EACd;EAsBA,OAAOtC,GAAakC,GAAmD;AACrE,QAAI,OAAOlC,KAAQ;AAAU,YAAM,IAAI,MAAM,sBAAsB;AAEnE,SAAK,QAAQ;AACb,UAAML,IAAO0C,EAAW,KAAK,OAAOrC,CAAG;AAEvC,WAAAL,EAAK,IAAIJ,GAAM2C,EAAGvC,EAAK,IAAIJ,CAAI,CAAC,CAAC,GAE1B;EACT;EAkBA,MAAMS,GAAauC,GAAqB;AACtC,QAAI,OAAOvC,KAAQ;AAAU,YAAM,IAAI,MAAM,sBAAsB;AAEnE,SAAK,QAAQ;AACb,UAAML,IAAO0C,EAAW,KAAK,OAAOrC,CAAG;AAEvC,QAAIH,IAAQF,EAAK,IAAIJ,CAAI;AAEzB,WAAIM,MAAU,UAAWF,EAAK,IAAIJ,GAAOM,IAAQ0C,EAAQ,CAAE,GAEpD1C;EACT;EAMA,SAAoC;AAClC,WAAO,IAAIL,EAAa,MAAMF,CAAM;EACtC;EAKA,CAAC,OAAO,QAAQ,IAAgC;AAC9C,WAAO,KAAK,QAAA;EACd;EAQA,OAAO,KACLkD,GACkB;AAClB,UAAMZ,IAAO,IAAID;AAEjB,eAAW,CAAC3B,GAAKH,CAAK,KAAK2C;AAASZ,QAAK,IAAI5B,GAAKH,CAAK;AAEvD,WAAO+B;EACT;EAQA,OAAO,WAAoBa,GAAgD;AACzE,WAAOd,GAAc,KAAQ,OAAO,QAAQc,CAAM,CAAC;EACrD;AACF;AAEA,IAAMX,IAAY,CAChBF,GACA5B,GACA6B,IAAgB,CAAA,MACwB;AACxC,MAAI7B,EAAI,WAAW,KAAK4B,KAAQ;AAAM,WAAO,CAACA,GAAMC,CAAI;AAExD,aAAWa,KAAWd,EAAK,KAAA;AACzB,QAAIc,MAAYnD,KAAQS,EAAI,WAAW0C,CAAO;AAC5C,aAAAb,EAAK,KAAK,CAACD,GAAMc,CAAO,CAAC,GAElBZ,EAAUF,EAAK,IAAIc,CAAO,GAAG1C,EAAI,MAAM0C,EAAQ,MAAM,GAAGb,CAAI;AAGvE,SAAAA,EAAK,KAAK,CAACD,GAAM5B,CAAG,CAAC,GAEd8B,EAAU,QAAW,IAAID,CAAI;AACtC;AAjBA,IAmBMO,IAAS,CACbR,GACA5B,MAC6B;AAC7B,MAAIA,EAAI,WAAW,KAAK4B,KAAQ;AAAM,WAAOA;AAE7C,aAAWc,KAAWd,EAAK,KAAK;AAC9B,QAAIc,MAAYnD,KAAQS,EAAI,WAAW0C,CAAO;AAC5C,aAAON,EAAOR,EAAK,IAAIc,CAAO,GAAI1C,EAAI,MAAM0C,EAAQ,MAAM,CAAC;AACjE;AA5BA,IAiCML,IAAa,CAAU1C,GAAoBK,MAA8B;AAC7E,QAAM2C,IAAY3C,EAAI;AAEtB4C;AAAO,aAAS7B,IAAM,GAAGpB,KAAQoB,IAAM4B,KAAa;AAElD,iBAAWX,KAAKrC,EAAK,KAAA;AACnB,YAAIqC,MAAMzC,KAAQS,EAAIe,CAAG,MAAMiB,EAAE,CAAC,GAAG;AACnC,gBAAMa,IAAM,KAAK,IAAIF,IAAY5B,GAAKiB,EAAE,MAAM;AAG9C,cAAInB,IAAS;AAEb,iBAAOA,IAASgC,KAAO7C,EAAIe,IAAMF,CAAM,MAAMmB,EAAEnB,CAAM;AAAG,cAAEA;AAE1D,gBAAMd,IAAQJ,EAAK,IAAIqC,CAAC;AAExB,cAAInB,MAAWmB,EAAE;AAEfrC,gBAAOI;eACF;AAGL,kBAAM+C,IAAe,oBAAI;AAEzBA,cAAa,IAAId,EAAE,MAAMnB,CAAM,GAAGd,CAAK,GACvCJ,EAAK,IAAIK,EAAI,MAAMe,GAAKA,IAAMF,CAAM,GAAGiC,CAAY,GACnDnD,EAAK,OAAOqC,CAAC,GACbrC,IAAOmD;UACT;AAEA/B,eAAOF;AACP,mBAAS+B;QACX;AAGF,YAAM7C,IAAQ,oBAAI;AAElB,aAAAJ,EAAK,IAAIK,EAAI,MAAMe,CAAG,GAAGhB,CAAK,GAEvBA;IACT;AAEA,SAAOJ;AACT;AA5EA,IA8EMsC,KAAS,CAAUL,GAAoB5B,MAAsB;AACjE,QAAM,CAACL,GAAMkC,CAAI,IAAIC,EAAUF,GAAM5B,CAAG;AAExC,MAAIL,MAAS,QAAA;AAIb,QAFAA,EAAK,OAAOJ,CAAI,GAEZI,EAAK,SAAS;AAChBoD,QAAQlB,CAAI;aACHlC,EAAK,SAAS,GAAG;AAC1B,YAAM,CAACK,GAAKH,CAAK,IAEhBF,EAAK,QAAA,EAAU,KAAQ,EAAA;AAExBqD,QAAMnB,GAAM7B,GAAKH,CAAK;IACxB;EAAA;AACF;AA9FA,IAgGMkD,IAAoBlB,OAAwB;AAChD,MAAIA,EAAK,WAAW;AAAG;AAEvB,QAAM,CAAClC,GAAMK,CAAG,IAAIF,EAAK+B,CAAI;AAI7B,MAFAlC,EAAM,OAAOK,CAAG,GAEZL,EAAM,SAAS;AACjBoD,MAAQlB,EAAK,MAAM,GAAG,EAAE,CAAC;WAChBlC,EAAM,SAAS,GAAG;AAC3B,UAAM,CAACK,GAAKH,CAAK,IAEhBF,EAAM,QAAU,EAAA,KAAA,EAAQ;AAErBK,UAAQT,KAAMyD,EAAMnB,EAAK,MAAM,GAAG,EAAE,GAAG7B,GAAKH,CAAK;EACvD;AACF;AAhHA,IAkHMmD,IAAQ,CACZnB,GACA7B,GACAH,MACS;AACT,MAAIgC,EAAK,WAAW;AAAG;AAEvB,QAAM,CAAClC,GAAMsD,CAAO,IAAInD,EAAK+B,CAAI;AAEjClC,IAAM,IAAIsD,IAAUjD,GAAKH,CAAK,GAC9BF,EAAM,OAAOsD,CAAO;AACtB;AA7HA,IA+HMnD,IAAiBG,OACdA,EAAMA,EAAM,SAAS,CAAC;AAhI/B,IChUaiD,IAAM,CACjBC,GACAC,MACYD,EAAY,aAAa,IAAIC,CAAE;AD6T7C,ICnTaC,KAAkB,CAC7BF,GACAC,MACwC;AACxC,QAAME,IAAUH,EAAY,aAAa,IAAIC,CAAE;AAE/C,MAAIE,KAAW;AAEf,WAAOH,EAAY,cAAc,IAAIG,CAAO;AAC9C;AD0SA,IEvUaC,KACX;AFsUF,IEpUaC,IAAK;AFoUlB,IEnUaC,IAAM;AFmUnB,IElUaC,KAAU;AFkUvB,IGlUaC,KAAmB,CAACC,GAAkBC,MAAuB;AAEnED,IAAO,SAASC,CAAI,KAAGD,EAAO,KAAKC,CAAI;AAC9C;AH+TA,IG7TaC,IAAoB,CAC/BF,GACAG,MACS;AAET,aAAWF,KAAQE;AAAaH,MAAO,SAASC,CAAI,KAAGD,EAAO,KAAKC,CAAI;AACzE;AHuTA,IGjTaG,IAAU,CAAC,EAAE,OAAOC,EAAE,GAAW,EAAE,OAAOC,EAAE,MACvDA,IAAID;AHgTN,IG9SaE,IAAY,MAAuB,oBAAI;AH8SpD,IG5SaC,IAA6B3B,OAEhB;AACxB,QAAM4B,IAAM,oBAAI;AAEhB,aAAWrE,KAAO,OAAO,KAAKyC,CAAM;AAClC4B,MAAI,IAAI,SAASrE,GAAK,EAAE,GAAGyC,EAAOzC,CAAG,CAAC;AAExC,SAAOqE;AACT;AHmSA,IGjSaC,IAAiB,CAAC7B,GAAa8B,MAC1C,OAAO,UAAU,eAAe,KAAK9B,GAAQ8B,CAAQ,IAEjD9B,EAAO8B,CAAQ,IACf;AH6RN,IGtQaC,KAAsD,EACjE,CAAChB,CAAE,GAAG,CAACS,GAAcC,MAAiB;AACpC,aAAWO,KAASP,EAAE,KAAA,GAAQ;AAC5B,UAAMQ,IAAWT,EAAE,IAAIQ,CAAK;AAE5B,QAAIC,KAAY;AACdT,QAAE,IAAIQ,GAAOP,EAAE,IAAIO,CAAK,CAAE;SACrB;AACL,YAAM,EAAE,OAAAE,GAAO,OAAAC,GAAO,OAAAC,EAAM,IAAIX,EAAE,IAAIO,CAAK;AAE3CC,QAAS,QAAQA,EAAS,QAAQC,GAClCD,EAAS,QAAQ,OAAO,OAAOA,EAAS,OAAOG,CAAK,GACpDf,EAAkBY,EAAS,OAAOE,CAAK;IACzC;EACF;AAEA,SAAOX;AACT,GACA,CAACR,CAAG,GAAG,CAACQ,GAAcC,MAAiB;AACrC,QAAMY,IAAW,oBAAI;AAErB,aAAWL,KAASP,EAAE,KAAK,GAAG;AAC5B,UAAMQ,IAAWT,EAAE,IAAIQ,CAAK;AAE5B,QAAIC,KAAY;AAAM;AAEtB,UAAM,EAAE,OAAAC,GAAO,OAAAC,GAAO,OAAAC,EAAM,IAAIX,EAAE,IAAIO,CAAK;AAE3CX,MAAkBY,EAAS,OAAOE,CAAK,GACvCE,EAAS,IAAIL,GAAO,EAClB,OAAOC,EAAS,QAAQC,GACxB,OAAOD,EAAS,OAChB,OAAO,OAAO,OAAOA,EAAS,OAAOG,CAAK,EAC5C,CAAC;EACH;AAEA,SAAOC;AACT,GACA,CAACpB,EAAO,GAAG,CAACO,GAAcC,MAAiB;AACzC,aAAWO,KAASP,EAAE,KAAK;AAAGD,MAAE,OAAOQ,CAAK;AAE5C,SAAOR;AACT,EACF;AH2NA,IGzNac,KAAgB,CAC3BC,GACAC,GACAC,GACAC,GACAC,GACAC,MACW;AACX,QAAM,EAAE,GAAArD,GAAG,GAAAkC,GAAG,GAAAoB,EAAE,IAAID;AAKpB,SAJmB,KAAK,IACtB,KAAKH,IAAaD,IAAgB,QAAQA,IAAgB,IAC5D,KAIGK,IACEN,KAAYhD,IAAI,MACdgD,IAAWhD,KAAK,IAAIkC,IAAKA,IAAIiB,IAAeC;AAErD;AHsMA,IG9LaG,KACVC,OACD,CAAC3B,GAAcnD,GAAWkE,MAA+B;AACvD,QAAMa,IACJ,OAAOD,EAAQ,SAAU,aACrBA,EAAQ,MAAM3B,GAAMnD,GAAGkE,CAAK,IAC5BY,EAAQ,SAAS,OACjB5E,IACJ,OAAO4E,EAAQ,UAAW,aACtBA,EAAQ,OAAO3B,GAAMnD,GAAGkE,CAAK,IAC7BY,EAAQ,WAAW;AAEzB,SAAO,EAAE,MAAA3B,GAAM,OAAA4B,GAAO,QAAA7E,EAAO;AAC/B;AHiLF,IIvUa8E,KAAsB,CACjCvC,GACAwC,GACAC,GACA/B,MACS;AACT,aAAWgC,KAAa,OAAO,KAAK1C,EAAY,SAAS;AACvD,QAAIA,EAAY,UAAU0C,CAAS,MAAMD,GAAS;AAChDzC,QAAY,SAAS,OACnB,QAEA,gCAAgCA,EAAY,aAAa,IACvDwC,CACF,CAAC,sCAAsC9B,CAAI,+BAA+BgC,CAAS,sEACnF,kBACF;AAEA;IACF;AACJ;AJoTA,IKlUaC,KAAU,CACrB3C,GACAyC,GACAG,GACAlC,MACS;AACT,QAAMmC,IAAY7C,EAAY,OAAO,MAAMU,GAAMM,CAAS;AAE1D,MAAI8B,IAAaD,EAAU,IAAIJ,CAAO;AAEtC,MAAIK,KAAc;AAChBA,QAAa,oBAAI,OACjBA,EAAW,IAAIF,GAAY,CAAC,GAC5BC,EAAU,IAAIJ,GAASK,CAAU;OAC5B;AACL,UAAMC,IAAOD,EAAW,IAAIF,CAAU;AAEtCE,MAAW,IAAIF,IAAaG,KAAQ,KAAK,CAAC;EAC5C;AACF;AL+SA,IK7SaC,IAAa,CACxBhD,GACAyC,GACAG,GACAlC,MACS;AACT,MAAI,CAACV,EAAY,OAAO,IAAIU,CAAI,GAAG;AACjC6B,OAAoBvC,GAAa4C,GAAYH,GAAS/B,CAAI;AAE1D;EACF;AAEA,QAAMmC,IAAY7C,EAAY,OAAO,MAAMU,GAAMM,CAAS,GAEpD8B,IAAaD,EAAU,IAAIJ,CAAO;AAEpCK,OAAc,QAAQA,EAAW,IAAIF,CAAU,KAAK,OACtDL,GAAoBvC,GAAa4C,GAAYH,GAAS/B,CAAI,IACnDoC,EAAW,IAAIF,CAAU,KAAM,IAClCE,EAAW,QAAQ,IAAGD,EAAU,OAAOJ,CAAO,IAC7CK,EAAW,OAAOF,CAAU,IAC9BE,EAAW,IAAIF,GAAYE,EAAW,IAAIF,CAAU,IAAK,CAAC,GAE3D5C,EAAY,OAAO,IAAIU,CAAI,EAAG,SAAS,KAAGV,EAAY,OAAO,OAAOU,CAAI;AAC9E;ALqRA,IMrUMuC,KAAiB,CACrBjD,GACA4C,GACAH,GACAS,GACAC,MACS;AACT,MAAIC,IAAepD,EAAY,aAAa,IAAI4C,CAAU;AAEtDQ,OAAgB,QAClBpD,EAAY,aAAa,IAAI4C,GAAaQ,IAAe,CAAG,CAAA,GAC9DA,EAAaX,CAAO,IAAIU;AAGxB,QAAME,KADqBrD,EAAY,gBAAgByC,CAAO,KAAK,KACrBS,IAAQC;AAEtDnD,IAAY,gBAAgByC,CAAO,IAAIY,KAAoBH,IAAQ;AACrE;ANoTA,IMlTMI,KAAgB,CACpBtD,GACA4C,MACW;AACX,QAAMJ,IAAkBxC,EAAY;AAEpC,SAAAA,EAAY,aAAa,IAAI4C,GAAYJ,CAAe,GACxDxC,EAAY,aAAa,IAAIwC,GAAiBI,CAAU,GACxD5C,EAAY,kBAAkB,GAC9BA,EAAY,WAAW,GAEhBwC;AACT;ANsSA,IMpSMe,KAAmB,CACvBvD,GACA4C,GACAY,MACS;AACT,QAAM,EAAE,aAAAC,GAAa,cAAAC,EAAa,IAAI1D,EAAY;AAElD,MAAIyD,KAAe,QAAQA,EAAY,WAAW;AAAG;AAErD,MAAIE,IAAiB3D,EAAY,cAAc,IAAI4C,CAAU;AAEzDe,OAAkB,QACpB3D,EAAY,cAAc,IAAI4C,GAAae,IAAiB,CAAA,CAAG;AAEjE,aAAWjB,KAAae,GAAa;AACnC,UAAMG,IAAaF,EAAaF,GAAKd,CAAS;AAE1CkB,UAAe,WAAWD,EAAejB,CAAS,IAAIkB;EAC5D;AACF;ANiRA,IMzQaC,IAAM,CACjB7D,GACA8D,MACS;AACT,QAAM,EAAE,cAAAJ,GAAc,UAAAK,GAAU,aAAAC,GAAa,QAAAC,GAAQ,SAAAC,EAAQ,IAC3DlE,EAAY,UACRC,IAAKyD,EAAaI,GAAUI,CAAO;AAEzC,MAAIjE,KAAM;AACR,UAAM,IAAI,MAAM,gDAAgDiE,CAAO,GAAG;AAE5E,MAAInE,EAAIC,GAAaC,CAAE;AAAG,UAAM,IAAI,MAAM,4BAA4BA,CAAE,EAAE;AAG1E,QAAMuC,IAAkBc,GAActD,GAAaC,CAAE;AAErDsD,KAAiBvD,GAAawC,GAAiBsB,CAAQ;AAEvD,aAAWK,KAASF,GAAQ;AAC1B,UAAML,IAAaF,EAAaI,GAAUK,CAAK;AAE/C,QAAIP,KAAc;AAAM;AAExB,UAAMQ,IAASL,EAASH,EAAW,SAAS,GAAGO,CAAK,GAC9C1B,IAAUzC,EAAY,UAAUmE,CAAK,GAErCE,IAAc,IAAI,IAAID,CAAM,EAAE;AAEpCnB,OACEjD,GACAwC,GACAC,GACAzC,EAAY,iBAAiB,GAC7BqE,CACF;AAEA,eAAW3D,KAAQ0D,GAAQ;AACzB,YAAME,IAAgBN,EAAYtD,GAAMyD,CAAK;AAE7C,UAAI,MAAM,QAAQG,CAAa;AAC7B,mBAAWC,KAAKD;AACd3B,aAAQ3C,GAAayC,GAASD,GAAiB+B,CAAC;;AAC3CD,aACP3B,GAAQ3C,GAAayC,GAASD,GAAiB8B,CAAa;IAChE;EACF;AACF;AN2NA,IMnNaE,IAAS,CACpBxE,GACAyE,MACS;AACT,aAAWX,KAAYW;AAAWZ,MAAI7D,GAAa8D,CAAQ;AAC7D;AN8MA,IMhMaY,KAAc,CACzB1E,GACAyE,GACApC,IAAkC,CAAA,MAChB;AAClB,QAAM,EAAE,WAAAsC,IAAY,GAAG,IAAItC,GACrBuC,IAAqD,EACzD,OAAO,CAAA,GACP,SAAS,QAAQ,QAAQ,EAC3B,GAEM,EAAE,OAAAC,GAAO,SAAAC,EAAQ,IAAIL,EAAU,OACnC,CAAC,EAAE,OAAAI,GAAO,SAAAC,EAAQ,GAAGhB,GAAUiB,OAC7BF,EAAM,KAAKf,CAAQ,IACdiB,IAAQ,KAAKJ,MAAc,IACvB,EACL,OAAO,CAAA,GACP,SAASG,EACN,KAAK,MAAM,IAAI,QAASE,OAAY,WAAWA,GAAS,CAAC,CAAC,CAAC,EAC3D,KAAK,MAAMR,EAAOxE,GAAa6E,CAAK,CAAC,EAC1C,IACU,EAAE,OAAAA,GAAO,SAAAC,EAAQ,IAE/BF,CACF;AAEA,SAAOE,EAAQ,KAAK,MAAMN,EAAOxE,GAAa6E,CAAK,CAAC;AACtD;ANqKA,IOrUaI,KAAgC,EAAE,GAAG,KAAK,GAAG,KAAK,GAAG,IAAI;APqUtE,IOnUaC,IAAiB,EAC5B,SAAS,MACT,cAAc,CAACpB,GAAepB,MAE5BoB,EAASpB,CAAS,GACpB,UAAWyC,OAA2BA,EAAK,MAAM/E,EAAoB,GACrE,aAAcM,OAAyBA,EAAK,YAC5C,GAAA,QAAQ,QACR,eAAe,QACf,aAAa,CAAA,GACb,QAAQ,CAAC0E,GAAiBC,MAA0B;AAC9C,UAAO,WAAA,OAAA,SAAA,QAAUD,CAAW,MAAA,cAAY,QAAQA,CAAK,EAAEC,CAAO;AACpE,GACA,YAAY,KACd;APqTA,IOnTaC,KAAuB,EAClC,aAAajF,GACb,QAAQ,OACR,OAAO,OACP,UAAU,GACV,OAAO,CAAC,GACR,SAAS,EAAE,OAAO,MAAM,QAAQ,MAAM,GACtC,MAAM4E,GACR;AP2SA,IOzSaM,KAA4B,EACvC,aAAajF,GACb,QAAQ,CAACkF,GAAeT,GAAetD,MACrCsD,MAAUtD,EAAM,SAAS,EAC7B;APqSA,IOnSagE,IAAuB,EAAE,WAAW,KAAM,WAAW,GAAG;APmSrE,IOlSaC,IAA0B,EAAE,eAAe,KAAK,cAAc,GAAG;APkS9E,IOhSaC,IAA2B,EACtC,GAAGF,GACH,GAAGC,EACL;AP6RA,IOtQaE,KAAmBC,OAAgC;AAE9D,MAAIX,EAAe,eAAeW,CAAU;AAC1C,WAAO1E,EAAe+D,GAAgBW,CAAU;AAC7C,QAAM,IAAI,MAAM,+BAA+BA,CAAU,GAAG;AACnE;APiQA,IQnSMC,KAAiB,CAAC5I,GAAsB6I,IAAc1F,MAAkB;AAC5E,MAAInD,EAAQ,WAAW;AAAG,WAAO,oBAAI;AAErC,QAAM8I,IAAWD,EAAY,YAAA;AAE7B,SAAO7I,EAAQ,OAAOmE,GAAY2E,CAAQ,CAAC,KAAK,oBAAI;AACtD;AR6RA,IQ3RMC,IAAc,CAClBjG,GACAkG,GACAC,GACAC,GACAC,GACAC,GACAC,GAGArE,GACAhF,IAAqB,oBAAI,UACX;AACd,MAAImJ,KAAiB;AAAM,WAAOnJ;AAElC,aAAWiH,KAAS,OAAO,KAAKmC,CAAW,GAAG;AAC5C,UAAME,IAAaF,EAAYnC,CAAK,GAC9B1B,IAAUzC,EAAY,UAAUmE,CAAK,GAErCsC,IAAuBJ,EAAc,IAAI5D,CAAO;AAEtD,QAAIgE,KAAwB;AAAM;AAElC,QAAIC,IAAiBD,EAAqB;AAC1C,UAAMxE,IAAiBjC,EAAY,gBAAgByC,CAAO;AAE1D,eAAWnB,KAASmF,EAAqB,KAAK,GAAG;AAC/C,UAAI,CAACzG,EAAY,aAAa,IAAIsB,CAAK,GAAG;AACxC0B,UAAWhD,GAAayC,GAASnB,GAAO6E,CAAW,GACnDO,KAAkB;AAClB;MACF;AAEA,YAAMC,IAAWJ,IACbA,EACEvG,EAAY,aAAa,IAAIsB,CAAK,GAClC6E,GACAnG,EAAY,cAAc,IAAIsB,CAAK,CACrC,IACA;AAEJ,UAAI,CAACqF;AAAU;AAEf,YAAM9E,IAAW4E,EAAqB,IAAInF,CAAK,GACzCU,IAAchC,EAAY,aAAa,IAAIsB,CAAK,EAAGmB,CAAO,GAQ1DmE,IAAWhF,GACfC,GACA6E,GACA1G,EAAY,gBACZgC,GACAC,GACAC,CACF,GACM2E,IAAgBT,IAAaI,IAAaG,IAAWC,GAErDE,IAAS5J,EAAQ,IAAIoE,CAAK;AAEhC,UAAIwF,GAAQ;AACVA,UAAO,SAASD,GAChBrG,GAAiBsG,EAAO,OAAOZ,CAAU;AACzC,cAAMxE,IAAkBP,EAAe2F,EAAO,OAAOX,CAAW;AAE5DzE,YAAOA,EAAM,KAAKyC,CAAK,IACtB2C,EAAO,MAAMX,CAAW,IAAI,CAAChC,CAAK;MACzC;AACEjH,UAAQ,IAAIoE,GAAO,EACjB,OAAOuF,GACP,OAAO,CAACX,CAAU,GAClB,OAAO,EAAE,CAACC,CAAW,GAAG,CAAChC,CAAK,EAAE,EAClC,CAAC;IAEL;EACF;AAEA,SAAOjH;AACT;ARyMA,IQvMM6J,KAAmB,CACvB/G,GACAhD,GACAgK,MACc;AACd,QAAM3E,IAAqC,EACzC,GAAGrC,EAAY,SAAS,eACxB,GAAGgH,EACL,GAEMC,KAAU5E,EAAQ,UAAUrC,EAAY,SAAS,QAAQ,OAC7D,CAACiH,GAAQ9C,OAAW,EAClB,GAAG8C,GACH,CAAC9C,CAAK,GAAGhD,EAAekB,EAAQ,OAAO8B,CAAK,KAAK,EACnD,IACA,CACF,CAAA,GAEM,EAAE,eAAA+C,GAAe,SAAAC,GAAS,UAAAC,GAAU,MAAMlF,EAAW,IAAIG,GAEzD,EAAE,OAAOgF,GAAa,QAAQC,EAAa,IAAI,EACnD,GAAGhC,GAAqB,SACxB,GAAG6B,EACL,GAEMI,IAAOvH,EAAY,OAAO,IAAIhD,EAAM,IAAI,GACxCE,IAAU+I,EACdjG,GACAhD,EAAM,MACNA,EAAM,MACN,GACAuK,GACAN,GACAC,GACAhF,CACF;AAEA,MAAIsF,GACAC;AAIJ,MAFIzK,EAAM,WAAQwK,IAAgBxH,EAAY,OAAO,SAAShD,EAAM,IAAI,IAEpEA,EAAM,OAAO;AACf,UAAMsF,IAAQtF,EAAM,UAAU,OAAO,MAAMA,EAAM,OAC3CC,IACJqF,IAAQ,IACJ,KAAK,IAAI8E,GAAU,KAAK,MAAMpK,EAAM,KAAK,SAASsF,CAAK,CAAC,IACxDA;AAEFrF,UACFwK,IAAezH,EAAY,OAAO,SAAShD,EAAM,MAAMC,CAAW;EACtE;AAEA,MAAIuK;AACF,eAAW,CAAC9G,GAAM6G,CAAI,KAAKC,GAAe;AACxC,YAAM7J,IAAW+C,EAAK,SAAS1D,EAAM,KAAK;AAE1C,UAAI,CAACW;AAAU;AAKf8J,WAAA,QAAAA,EAAc,OAAO/G,CAOrB;AAAA,YAAMgH,IACHJ,IAAe5G,EAAK,UAAWA,EAAK,SAAS,MAAM/C;AAEtDsI,QACEjG,GACAhD,EAAM,MACN0D,GACAgH,GACAH,GACAN,GACAC,GACAhF,GACAhF,CACF;IACF;AAEF,MAAIuK;AACF,eAAW/G,KAAQ+G,EAAa,KAAK,GAAG;AACtC,YAAM,CAACF,GAAM5J,CAAQ,IAAI8J,EAAa,IAAI/G,CAAI;AAE9C,UAAI,CAAC/C;AAAU;AAKf,YAAM+J,IAAUL,IAAc3G,EAAK,UAAWA,EAAK,SAAS/C;AAE5DsI,QACEjG,GACAhD,EAAM,MACN0D,GACAgH,GACAH,GACAN,GACAC,GACAhF,GACAhF,CACF;IACF;AAEF,SAAOA;AACT;ARyFA,IQvFayK,KAAe,CAC1B3H,GACAhD,GACAgK,IAAmC,CACrB,MAAA;AACd,MAAI,OAAOhK,KAAU,UAAU;AAC7B,UAAMqF,IAAU,EAAE,GAAG2E,GAAe,GAAGhK,GAAO,SAAS,OAAU,GAC3DE,IAAUF,EAAM,QAAQ,IAAK4K,OACjCD,GAAa3H,GAAa4H,GAAUvF,CAAO,CAC7C;AAEA,WAAOyD,GAAe5I,GAASmF,EAAQ,WAAW;EACpD;AAEA,QAAM,EACJ,UAAA0B,GACA,aAAAC,GACA,eAAe6D,EACjB,IAAI7H,EAAY,UACVqC,IAAU,EACd,UAAA0B,GACA,aAAAC,GACA,GAAG6D,GACH,GAAGb,EACL,GACM,EAAE,UAAUc,GAAgB,aAAaC,EAAkB,IAAI1F,GAQ/DnF,IANQ4K,EAAe9K,CAAK,EAE/B,QAAS0D,OAAiBqH,EAAkBrH,CAAI,CAAC,EACjD,OAAQA,OAAS,CAAC,CAACA,CAAI,EAES,IAAI0B,GAAgBC,CAAO,CAAC,EACvC,IAAKrF,OAE3B+J,GAAiB/G,GAAahD,GAAOqF,CAAO,CAC9C;AAEA,SAAOyD,GAAe5I,GAASmF,EAAQ,WAAW;AACpD;ARgDA,ISrLa2F,KAAS,CAKpBhI,GACAhD,GACAgK,IAAmC,CAAA,MACL;AAC9B,QAAMiB,IAAkBN,GAAa3H,GAAahD,GAAOgK,CAAa,GAEhE9J,IAAqC,CAAC;AAE5C,aAAW,CAACoE,GAAO,EAAE,OAAAE,GAAO,OAAAC,GAAO,OAAAC,EAAM,CAAC,KAAKuG,GAAiB;AAG9D,UAAMC,IAAUzG,EAAM,QAEhBqF,IAAS,EACb,IAAI9G,EAAY,aAAa,IAAIsB,CAAK,GACtC,OAAOE,IAAQ0G,GACf,OAAO,OAAO,KAAKxG,CAAK,GACxB,OAAAA,EACF;AAEA,WAAO,OAAOoF,GAAQ9G,EAAY,cAAc,IAAIsB,CAAK,CAAC,IACtD0F,EAAc,UAAU,QAAQA,EAAc,OAAOF,CAAM,MAC7D5J,EAAQ,KAA8B4J,CAAM;EAChD;AAEA,SAAA5J,EAAQ,KAAK2D,CAAO,GAEb3D;AACT;AToJA,IUvQaiL,KAAc,CACzBnI,GACAoI,GACA/F,IAA6B,CAAA,MACZ;AACjBA,MAAU,EAAE,GAAGrC,EAAY,SAAS,oBAAoB,GAAGqC,EAAQ;AAEnE,QAAMgG,IAGF,oBAAI;AAER,aAAW,EAAE,OAAA7G,GAAO,OAAAC,EAAM,KAAKuG,GAAOhI,GAAaoI,GAAa/F,CAAO,GAAG;AACxE,UAAMiG,IAAS7G,EAAM,KAAK,GAAG,GACvB8G,IAAaF,EAAY,IAAIC,CAAM;AAErCC,SAAc,QAChBA,EAAW,SAAS/G,GACpB+G,EAAW,SAAS,KAEpBF,EAAY,IAAIC,GAAQ,EAAE,OAAA9G,GAAO,OAAAC,GAAO,OAAO,EAAE,CAAC;EAEtD;AAEA,QAAMvE,IAAU,CAAA;AAEhB,aAAW,CAACqL,GAAY,EAAE,OAAA/G,GAAO,OAAAC,GAAO,OAAAyB,EAAM,CAAC,KAAKmF;AAClDnL,MAAQ,KAAK,EAAE,YAAAqL,GAAY,OAAA9G,GAAO,OAAOD,IAAQ0B,EAAM,CAAC;AAE1D,SAAAhG,EAAQ,KAAK2D,CAAO,GAEb3D;AACT;ACKa,IAAAsL,KAAA,MAAsC;EAgBjD,YAAYnG,GAA2C;AAfvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE,SAAIA,KAAA,OAAAA,SAAAA,EAAS,WAAU;AACrB,YAAM,IAAI,MAAM,8CAA8C;AAEhE,UAAMoG,IACJpG,EAAQ,cAAc,QAAQA,EAAQ,eAAe,OACjDsD,IACAtD,EAAQ;AAGd,SAAK,WAAW,EACd,GAAG6C,GACH,GAAG7C,GACH,YAAAoG,GACA,eAAe,EACb,GAAGnD,IACH,GAAIjD,EAAQ,iBAAiB,CAC/B,EAAA,GACA,oBAAoB,EAClB,GAAGkD,IACH,GAAIlD,EAAQ,sBAAsB,CAAA,EACpC,EACF,GAEA,KAAK,SAAS,IAAI7D,KAElB,KAAK,iBAAiB,GAEtB,KAAK,eAAe,oBAAI,OAExB,KAAK,eAAe,oBAAI,OAMxB,KAAK,YAAY,CAAA,GAEjB,KAAK,eAAe,oBAAI,OAExB,KAAK,kBAAkB,CAAC,GAExB,KAAK,UAAU,GAEf,KAAK,gBAAgB,oBAAI,OAEzB,KAAK,aAAa,GAElB,KAAK,iBAAiB,MAEtB,KAAK,kBAAkB,MACvB,KAAK,4BAA4BkH,GAEjC,KAAK,UAAU,KAAK,SAAS,MAAM;EACrC;EAKA,IAAI,cAAuB;AACzB,WAAO,KAAK,kBAAkB;EAChC;EAKA,IAAI,YAAoB;AACtB,WAAO,KAAK;EACd;EASA,IAAI,aAAqB;AACvB,WAAO,KAAK,cAAc,IAAI,KAAK,iBAAiB,KAAK;EAC3D;EAKA,IAAI,gBAAwB;AAC1B,WAAO,KAAK;EACd;EAKA,IAAI,YAAoB;AACtB,WAAO,KAAK,OAAO;EACrB;EA0BA,SAAsB;AACpB,UAAMX,IAA6D,CAEnE;AAAA,eAAW,CAACrE,GAAMoC,CAAU,KAAK,KAAK,QAAQ;AAC5C,YAAMyE,IAAgD,CAEtD;AAAA,iBAAW,CAAC9E,GAASiG,CAAW,KAAK5F;AACnCyE,UAAK9E,CAAO,IAAI,OAAO,YAAYiG,CAAW;AAEhD3D,QAAM,KAAK,CAACrE,GAAM6G,CAAI,CAAC;IACzB;AAEA,WAAO,EACL,eAAe,KAAK,gBACpB,QAAQ,KAAK,SACb,aAAa,OAAO,YAAY,KAAK,YAAY,GACjD,UAAU,KAAK,WACf,aAAa,OAAO,YAAY,KAAK,YAAY,GACjD,oBAAoB,KAAK,iBACzB,cAAc,OAAO,YAAY,KAAK,aAAa,GACnD,WAAW,KAAK,YAChB,OAAAxC,GACA,sBAAsB,EACxB;EACF;EAKQ,UAAUd,GAAwB;AACxC,aAAS1G,IAAI,GAAGA,IAAI0G,EAAO,QAAQ1G;AAAK,WAAK,UAAU0G,EAAO1G,CAAC,CAAC,IAAIA;EACtE;AACF;ACtMO,IAAMoL,KACXtG,OAC8B,IAAImG,GAAYnG,CAAO;AAFhD,IAIMuG,KAAY,CACvB,EACE,OAAA7D,GACA,eAAA8D,GACA,QAAAC,GACA,aAAAC,GACA,UAAAC,GACA,aAAAhH,GACA,oBAAAiH,GACA,cAAAC,GACA,WAAAC,GACA,sBAAAC,EACF,GACA/G,MAC8B;AAC9B,MAAI+G,MAAyB,KAAKA,MAAyB;AACzD,UAAM,IAAI,MACR,8EACF;AAEF,QAAMpJ,IAAc,IAAIwI,GAAYnG,CAAO;AAE3CrC,IAAY,iBAAiB6I,GAC7B7I,EAAY,UAAU8I,GACtB9I,EAAY,eAAeiB,EAAuB8H,CAAW,GAC7D/I,EAAY,eAAe,oBAAI,OAC/BA,EAAY,YAAYgJ,GACxBhJ,EAAY,eAAeiB,EAAmBe,CAAW,GACzDhC,EAAY,kBAAkBiJ,GAC9BjJ,EAAY,gBAAgBiB,EAAmBiI,CAAY,GAC3DlJ,EAAY,aAAamJ,KAAa,GACtCnJ,EAAY,SAAS,IAAIxB;AAEzB,aAAW,CAAC2B,GAASF,CAAE,KAAKD,EAAY;AACtCA,MAAY,aAAa,IAAIC,GAAIE,CAAO;AAE1C,aAAW,CAACO,GAAM6G,CAAI,KAAKxC,GAAO;AAChC,UAAMsE,IAAU,oBAAI;AAEpB,eAAW5G,KAAW,OAAO,KAAK8E,CAAI,GAAG;AACvC,UAAI+B,IAAa/B,EAAK9E,CAAO;AAGzB2G,YAAyB,MAC3BE,IAAaA,EAAW,KAE1BD,EAAQ,IACN,SAAS5G,GAAS,EAAE,GACpBxB,EAAmBqI,CAAU,CAC/B;IACF;AAEAtJ,MAAY,OAAO,IAAIU,GAAM2I,CAAO;EACtC;AAEA,SAAOrJ;AACT;AA5DO,IAoFMuJ,KAAgB,CAC3BC,GACAnH,MAC8B;AAC9B,MAAIA,KAAW;AACb,UAAM,IAAI,MACR,uFACF;AAEF,SAAOuG,GAAuB,KAAK,MAAMY,CAAI,GAAGnH,CAAO;AACzD;AA9FO,IChEDoH,KAAe,CACnBzJ,GACA0J,MACY;AACZ,MAAIA,KAAc;AAAM,WAAO;AAE/B,QAAM,EACJ,cAAAC,IAAehE,EAAyB,cACxC,eAAAiE,IAAgBjE,EAAyB,cAC3C,IAAI+D;AAEJ,SACE1J,EAAY,aAAa2J,KACzB3J,EAAY,cAAc4J;AAE9B;ADiDO,IC/CDC,KAAW,OACf7J,GACAqC,GACAqH,MACkB;AAClB,QAAMI,IAAmB9J,EAAY;AAErC,MAAIyJ,GAAazJ,GAAa0J,CAAU,GAAG;AACzC,UAAMK,IAAY1H,EAAQ,aAAaoD,EAAqB,WACtDuE,IAAY3H,EAAQ,aAAaoD,EAAqB;AAC5D,QAAIlI,IAAI;AAER,eAAW,CAACmD,GAAMuJ,CAAU,KAAKjK,EAAY,QAAQ;AACnD,iBAAW,CAACyC,GAASK,CAAU,KAAKmH;AAClC,mBAAW,CAAC9J,CAAO,KAAK2C;AAClB9C,YAAY,aAAa,IAAIG,CAAO,MAEpC2C,EAAW,QAAQ,IAAGmH,EAAW,OAAOxH,CAAO,IAC9CK,EAAW,OAAO3C,CAAO;AAG9BH,QAAY,OAAO,IAAIU,CAAI,EAAG,SAAS,KACzCV,EAAY,OAAO,OAAOU,CAAI,GAE5BnD,IAAIwM,MAAc,KACpB,MAAM,IAAI,QAAS/E,OAAY,WAAWA,GAASgF,CAAS,CAAC,GAE/DzM,KAAK;IACP;AAEAyC,MAAY,cAAc8J;EAC5B;AAIA,QAAM,MAEN9J,EAAY,iBAAiBA,EAAY,iBACzCA,EAAY,kBAAkB;AAChC;ADQO,ICNDkK,KAAoB,CACxBlK,GACAqC,GACAqH,MAMI1J,EAAY,kBACdA,EAAY,4BACVA,EAAY,6BAA6B0J,GACvC1J,EAAY,mBAAmB,SAEnCA,EAAY,kBAAkBA,EAAY,eAAe,KAAK,MAAM;AAClE,QAAM0J,IAAa1J,EAAY;AAE/B,SAAAA,EAAY,4BAA4B0F,GAEjCmE,GAAS7J,GAAaqC,GAASqH,CAAU;AAClD,CAAC,IAEM1J,EAAY,mBAGjByJ,GAAazJ,GAAa0J,CAAU,MAAM,QAAc,QAAQ,QAAQ,KAE5E1J,EAAY,iBAAiB6J,GAAS7J,GAAaqC,CAAO,GAEnDrC,EAAY;ADvBd,IC0BMmK,KACXnK,OACS;AACT,MAAIA,EAAY,SAAS,eAAe;AAAO;AAE/C,QAAM,EAAE,eAAA4J,GAAe,cAAAD,GAAc,WAAAI,GAAW,WAAAC,EAAU,IACxDhK,EAAY,SAAS;AAElBkK,KACHlK,GACA,EAAE,WAAA+J,GAAW,WAAAC,EAAU,GACvB,EAAE,cAAAL,GAAc,eAAAC,EAAc,CAChC;AACF;ADvCO,ICiFMQ,KAAS,CACpBpK,GACAqC,IAAyB,CAAA,MACP6H,GAAkBlK,GAAaqC,CAAO;ADpFnD,IEnEDgI,KAAoB,CACxBrK,GACAyC,GACAS,GACAC,MACS;AACT,MAAID,MAAU,GAAG;AACflD,MAAY,gBAAgByC,CAAO,IAAI;AAEvC;EACF;AAEA,QAAMY,IACJrD,EAAY,gBAAgByC,CAAO,IAAIS,IAAQC;AAEjDnD,IAAY,gBAAgByC,CAAO,IAAIY,KAAoBH,IAAQ;AACrE;AFmDO,IELMoH,IAAU,CACrBtK,GACAC,MACS;AACT,QAAME,IAAUH,EAAY,aAAa,IAAIC,CAAE;AAE/C,MAAIE,KAAW;AACb,UAAM,IAAI,MACR,+CACEF,CACD,0BACH;AAEFD,IAAY,aAAa,OAAOC,CAAE,GAClCD,EAAY,aAAa,OAAOG,CAAO,GACvCH,EAAY,cAAc,OAAOG,CAAO,IACvCH,EAAY,aAAa,IAAIG,CAAO,KAAK,CAAA,GAAI,QAC5C,CAAC6B,GAAaS,MAAY;AACxB4H,OACErK,GACAyC,GACAzC,EAAY,gBACZgC,CACF;EACF,CACF,GAEAhC,EAAY,aAAa,OAAOG,CAAO,GAEvCH,EAAY,kBAAkB,GAC9BA,EAAY,cAAc,GAE1BmK,GAAgBnK,CAAW;AAC7B;AF5BO,IE0CMuK,KAAa,CACxBvK,GACAwK,MACS;AACT,QAAM/B,IAAazI,EAAY,SAAS;AAExC,MAAI;AACFA,MAAY,SAAS,aAAa;AAElC,eAAWC,KAAMuK;AAAKF,QAAQtK,GAAaC,CAAE;EAC/C,UAAA;AACED,MAAY,SAAS,aAAayI;EACpC;AAEA0B,KAAgBnK,CAAW;AAC7B;AFzDO,IE0EMlB,KAAS,CACpBkB,GACA8D,MACS;AACT,QAAM,EAAE,UAAAC,GAAU,aAAAC,GAAa,cAAAN,GAAc,QAAAO,GAAQ,SAAAC,EAAQ,IAC3DlE,EAAY,UACRC,IAASyD,EAAaI,GAAUI,CAAO;AAE7C,MAAIjE,KAAM;AACR,UAAM,IAAI,MAAM,gDAAgDiE,CAAO,GAAG;AAE5E,QAAM/D,IAAUH,EAAY,aAAa,IAAIC,CAAE;AAE/C,MAAIE,KAAW;AACb,UAAM,IAAI,MACR,8CACEF,CACD,0BACH;AAEF,aAAWkE,KAASF,GAAQ;AAC1B,UAAML,IAAaF,EAAaI,GAAUK,CAAK;AAE/C,QAAIP,KAAc;AAAM;AAExB,UAAMQ,IAASL,EAASH,EAAW,SAAA,GAAYO,CAAK,GAC9C1B,IAAUzC,EAAY,UAAUmE,CAAK,GAErCE,IAAc,IAAI,IAAID,CAAM,EAAE;AAEpCiG,OACErK,GACAyC,GACAzC,EAAY,gBACZqE,CACF;AAEA,eAAW3D,KAAQ0D,GAAQ;AACzB,YAAME,IAAgBN,EAAYtD,GAAMyD,CAAK;AAE7C,UAAI,MAAM,QAAQG,CAAa;AAC7B,mBAAWC,KAAKD;AACdtB,YAAWhD,GAAayC,GAAStC,GAASoE,CAAC;;AACtCD,aACPtB,EAAWhD,GAAayC,GAAStC,GAASmE,CAAa;IAC3D;EACF;AAEAtE,IAAY,cAAc,OAAOG,CAAO,GACxCH,EAAY,aAAa,OAAOG,CAAO,GACvCH,EAAY,aAAa,OAAOC,CAAE,GAClCD,EAAY,aAAa,OAAOG,CAAO,GACvCH,EAAY,kBAAkB;AAChC;AF/HO,IE2IMyK,KAAY,SACvBzK,GACAyE,GACM;AACN,MAAIA;AACF,eAAWX,KAAYW;AAAW3F,SAAOkB,GAAa8D,CAAQ;OACzD;AAAA,QAAI,UAAU,SAAS;AAC5B,YAAM,IAAI,MACR,8EACF;AAEA9D,MAAY,SAAS,IAAIxB,KACzBwB,EAAY,iBAAiB,GAC7BA,EAAY,eAAe,oBAAI,OAC/BA,EAAY,eAAe,oBAAI,OAC/BA,EAAY,eAAe,oBAAI,OAC/BA,EAAY,kBAAkB,CAAA,GAC9BA,EAAY,gBAAgB,oBAAI,OAChCA,EAAY,UAAU;EAE1B;AAAA;AF/JO,IGpDM0K,KAAU,CACrB1K,GACA2K,MACS;AACT,QAAM,EAAE,SAAAzG,GAAS,cAAAR,EAAa,IAAI1D,EAAY,UACxCC,IAASyD,EAAaiH,GAAiBzG,CAAO;AAEpDoG,IAAQtK,GAAaC,CAAE,GACvB4D,EAAI7D,GAAa2K,CAAe;AAClC;",
  "names": ["ENTRIES", "KEYS", "VALUES", "LEAF", "TreeIterator", "set", "type", "node", "keys", "value", "last", "child", "key", "array", "fuzzySearch", "query", "maxDistance", "results", "n", "m", "matrix", "j", "i", "recurse", "prefix", "offset", "distance", "pos", "char", "thisRowOffset", "prevRowOffset", "minDistance", "jmin", "jmax", "different", "rpl", "del", "ins", "dist", "SearchableMap", "tree", "path", "trackDown", "parentNode", "k", "remove", "fn", "maxEditDistance", "lookup", "createPath", "iter", "initial", "entries", "object", "treeKey", "keyLength", "outer", "len", "intermediate", "cleanup", "merge", "nodeKey", "has", "searchIndex", "id", "getStoredFields", "shortId", "SPACE_OR_PUNCTUATION", "OR", "AND", "AND_NOT", "assignUniqueTerm", "target", "term", "assignUniqueTerms", "source", "byScore", "a", "b", "createMap", "objectToNumericMap", "map", "getOwnProperty", "property", "combinators", "docId", "existing", "score", "terms", "match", "combined", "calcBM25Score", "termFreq", "matchingCount", "totalCount", "fieldLength", "avgFieldLength", "bm25params", "d", "termToQuerySpec", "options", "fuzzy", "warnDocumentChanged", "shortDocumentId", "fieldId", "fieldName", "addTerm", "documentId", "indexData", "fieldIndex", "docs", "removeTerm", "addFieldLength", "count", "length", "fieldLengths", "totalFieldLength", "addDocumentId", "saveStoredFields", "doc", "storeFields", "extractField", "documentFields", "fieldValue", "add", "document", "tokenize", "processTerm", "fields", "idField", "field", "tokens", "uniqueTerms", "processedTerm", "t", "addAll", "documents", "addAllAsync", "chunkSize", "acc", "chunk", "promise", "index", "resolve", "defaultBM25params", "defaultOptions", "text", "level", "message", "defaultSearchOptions", "defaultAutoSuggestOptions", "_term", "defaultVacuumOptions", "defaultVacuumConditions", "defaultAutoVacuumOptions", "getDefaultValue", "optionName", "combineResults", "combineWith", "operator", "termResults", "sourceTerm", "derivedTerm", "termWeight", "fieldTermData", "fieldBoosts", "boostDocumentFn", "fieldBoost", "fieldTermFrequencies", "matchingFields", "docBoost", "rawScore", "weightedScore", "result", "executeQuerySpec", "searchOptions", "boosts", "boostDocument", "weights", "maxFuzzy", "fuzzyWeight", "prefixWeight", "data", "prefixMatches", "fuzzyMatches", "weight", "executeQuery", "subQuery", "globalSearchOptions", "searchTokenize", "searchProcessTerm", "search", "combinedResults", "quality", "autoSuggest", "queryString", "suggestions", "phrase", "suggestion", "SearchIndex", "autoVacuum", "frequencies", "createIndex", "loadIndex", "documentCount", "nextId", "documentIds", "fieldIds", "averageFieldLength", "storedFields", "dirtCount", "serializationVersion", "dataMap", "indexEntry", "loadJSONIndex", "json", "shouldVacuum", "conditions", "minDirtCount", "minDirtFactor", "doVacuum", "initialDirtCount", "batchSize", "batchWait", "fieldsData", "conditionalVacuum", "maybeAutoVacuum", "vacuum", "removeFieldLength", "discard", "discardAll", "ids", "removeAll", "replace", "updatedDocument"]
}
